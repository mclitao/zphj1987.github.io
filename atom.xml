<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[zphj1987'Blog]]></title>
  <subtitle><![CDATA[现在所学，终有所用]]></subtitle>
  <link href="/atom.xml" rel="self"/>
  <link href="http://www.zphj1987.com/"/>
  <updated>2016-01-25T09:17:30.690Z</updated>
  <id>http://www.zphj1987.com/</id>
  
  <author>
    <name><![CDATA[zphj1987]]></name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[磨磨谈 ceph-users 邮件列表之Vol-36-Issue-23]]></title>
    <link href="http://www.zphj1987.com/2016/01/25/%E7%A3%A8%E7%A3%A8%E8%B0%88-ceph-users-%E9%82%AE%E4%BB%B6%E5%88%97%E8%A1%A8%E4%B9%8BVol-36-Issue-23/"/>
    <id>http://www.zphj1987.com/2016/01/25/磨磨谈-ceph-users-邮件列表之Vol-36-Issue-23/</id>
    <published>2016-01-24T16:06:58.000Z</published>
    <updated>2016-01-25T09:17:30.690Z</updated>
    <content type="html"><![CDATA[<h2 id="前言：">前言：</h2><p>一个技术的邮件列表其实是个大宝藏，看你怎么去挖掘它了，里面有太多的灵光一现，太多的大牛的引导，而我等也只能在某些出现问题的时候，去搜索的时候，才发现这些问题是很多人遇到过的，最近看到一个技术人说的一句话深有同感,意思是说，很多时候我们花精力重复解决问题</p>
<ul>
<li>一流的公司在从整体上去解决一批的问题</li>
<li>二流的公司在一次又一次解决相同的问题</li>
</ul>
<p>与其等待别人去整理，还不如自己去做这个事情，没有压力，没有人催促，最后自己还能有所收获，何乐而不为，这个系列我会去将邮件列表的里面的内容进行整理，提出我个人的处理办法或者方式，或者总结一下里面别人的经验，这个系列将以现在的时间线往前和往后的方式进行整理，这个会是一个很长的过程，希望尽量的获取更多的东西，文档格式尽量保持一致</p>
<a id="more"></a>
<h3 id="一、今天的_Topics:">一、今天的 Topics:</h3><ol>
<li>journal encryption with dmcrypt (Reno Rainz)</li>
<li>Re: CephFS (Gregory Farnum)</li>
<li>Re: ceph fuse closing stale session while still   operable<br>(Gregory Farnum)</li>
<li>Re: ceph fuse closing stale session while still   operable<br>(Oliver Dzombic)</li>
<li>Re: ceph fuse closing stale session while still   operable<br>(Gregory Farnum)</li>
<li>Re: ceph fuse closing stale session while still   operable<br>(Oliver Dzombic)</li>
<li>Re: ceph-rest-api’s behavior (Shinobu Kinjo)</li>
</ol>
<hr>
<h3 id="二、涉及问题：">二、涉及问题：</h3><ul>
<li>journal encryption with dmcrypt</li>
<li>CephFS</li>
<li>ceph fuse closing stale session while still   operable</li>
</ul>
<h3 id="三、问题解析">三、问题解析</h3><h4 id="问题一：">问题一：</h4><p>journal encryption with dmcrypt （Reno Rainz）</p>
<p>问题原文：<br>I’m trying to setup a cluster with encryption on osd data and journal.<br>To do  that I use ceph-deploy with this 2 options —dmcrypt<br>—dmcrypt-key-dir on /dev/sdc disk.<br>……</p>
<p>分析：<br>问题的提出者试图在部署osd的时候使用 encryption 对 osd 进行加密,在用 ceph-deploy 的时候，部署的时候出现了失败</p>
<p>总结：</p>
<p>这个地方是因为 ceph-deploy 在进行 activate 操作的时候，把这个加密分区当做了 crypto_LUKS 分区格式进行了 mount 操作，这个肯定是不能成功的，因为这个加密盘是需要进行映射操作的，这里缺少了这个操作，不清楚是需要加其他的参数还是怎样，这个地方可以通过其他方式进行处理</p>
<p>在进行 ceph-deploy osd prepare 操作的时候，可以查看看到有一行这个，这个中间的 f6244401-c848-42d1-9096-9a3ee5a136e9 即为 osd 的 fsid<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Running <span class="built_in">command</span>: /usr/sbin/cryptsetup --batch-mode --key-file /root/keydir/f6244401-c848-<span class="number">42</span>d1-<span class="number">9096</span>-<span class="number">9</span>a3ee5a136e9.luks.key luksFormat /dev/sdd1</span><br></pre></td></tr></table></figure></p>
<p>等待osd prepare 操作做完了以后，就进行下面的操作</p>
<p>1、进行磁盘的映射<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cryptsetup --key-file /root/keydir/f6244401-c848-<span class="number">42</span>d1-<span class="number">9096</span>-<span class="number">9</span>a3ee5a136e9.luks.key luksOpen /dev/sdd1 f6244401-c848-<span class="number">42</span>d1-<span class="number">9096</span>-<span class="number">9</span>a3ee5a136e9</span><br></pre></td></tr></table></figure></p>
<p>2、进行osd的激活<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph-deploy osd activate /dev/mapper/f6244401-c848-<span class="number">42</span>d1-<span class="number">9096</span>-<span class="number">9</span>a3ee5a136e9</span><br></pre></td></tr></table></figure></p>
<p>这样就可以了</p>
<p>另外：<br>取消映射的操作是<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cryptsetup remove f6244401-c848-<span class="number">42</span>d1-<span class="number">9096</span>-<span class="number">9</span>a3ee5a136e9</span><br></pre></td></tr></table></figure></p>
<h4 id="问题二：">问题二：</h4><p>ceph fuse closing stale session while still   operable （Oliver Dzombic）</p>
<p>问题原文：<br>Hi,<br>i am testing on centos 6 x64 minimal install.<br>i am mounting successfully:<br>ceph-fuse -m 10.0.0.1:6789,10.0.0.2:6789,10.0.0.3:6789,10.0.0.4:6789<br>/ceph-storage/<br>……</p>
<p>分析：<br>问题的提出者在使用ceph-fuse去挂载集群的时候，写入一个大文件的时候出现无法写入的问题，在mds的日志当中可以看到<br>closing stale session client.21176728 10.0.0.91:0/1635 after 301.302291 的日志信息</p>
<p>从日志检查过程看<br>ceph -s 出现了  62 requests are blocked &gt; 32 sec<br>问题提出者在认证的时候，出现了语法错误 ceph auth list showed 可以检查，后经修改，还是问题一样</p>
<p>查看客户端的请求：<br>ceph daemon /var/run/ceph/ceph-client.admin.asok objecter_requests<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="string">"ops"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="string">"tid"</span>: <span class="number">12</span>,</span><br><span class="line">            <span class="string">"pg"</span>: <span class="string">"6.7230bd94"</span>,</span><br><span class="line">            <span class="string">"osd"</span>: <span class="number">1</span>,</span><br><span class="line">            <span class="string">"object_id"</span>: <span class="string">"10000000017.00000004"</span>,</span><br><span class="line">            <span class="string">"object_locator"</span>: <span class="string">"@6"</span>,</span><br><span class="line">            <span class="string">"target_object_id"</span>: <span class="string">"10000000017.00000004"</span>,</span><br><span class="line">            <span class="string">"target_object_locator"</span>: <span class="string">"@6"</span>,</span><br><span class="line">            <span class="string">"paused"</span>: <span class="number">0</span>,</span><br><span class="line">            <span class="string">"used_replica"</span>: <span class="number">0</span>,</span><br><span class="line">            <span class="string">"precalc_pgid"</span>: <span class="number">0</span>,</span><br><span class="line">            <span class="string">"last_sent"</span>: <span class="string">"2016-01-22 23:11:28.788800"</span>,</span><br><span class="line">            <span class="string">"attempts"</span>: <span class="number">95</span>,</span><br><span class="line">            <span class="string">"snapid"</span>: <span class="string">"head"</span>,</span><br><span class="line">            <span class="string">"snap_context"</span>: <span class="string">"1=[]"</span>,</span><br><span class="line">            <span class="string">"mtime"</span>: <span class="string">"2016-01-21 23:41:18.001327"</span>,</span><br><span class="line">            <span class="string">"osd_ops"</span>: [</span><br><span class="line">                <span class="string">"write 0~4194304 [5@0]"</span></span><br><span class="line">            ]</span><br></pre></td></tr></table></figure></p>
<p>其中<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="string">"attempts"</span>: <span class="number">95</span>,</span><br></pre></td></tr></table></figure></p>
<p>这个可以说明请求了95次还没有回应，从这个分析，应该是问题提出者的环境中的某个osd出现了问题，阻塞了请求</p>
<p>总结：<br>在无法写入的时候，可以查看下客户端的sock去查看哪个请求被阻塞了，然后去排查对应的osd即可</p>
<hr>
<p>文档最后更新时间：<br>2016年01月25日 </p>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="前言：">前言：</h2><p>一个技术的邮件列表其实是个大宝藏，看你怎么去挖掘它了，里面有太多的灵光一现，太多的大牛的引导，而我等也只能在某些出现问题的时候，去搜索的时候，才发现这些问题是很多人遇到过的，最近看到一个技术人说的一句话深有同感,意思是说，很多时候我们花精力重复解决问题</p>
<ul>
<li>一流的公司在从整体上去解决一批的问题</li>
<li>二流的公司在一次又一次解决相同的问题</li>
</ul>
<p>与其等待别人去整理，还不如自己去做这个事情，没有压力，没有人催促，最后自己还能有所收获，何乐而不为，这个系列我会去将邮件列表的里面的内容进行整理，提出我个人的处理办法或者方式，或者总结一下里面别人的经验，这个系列将以现在的时间线往前和往后的方式进行整理，这个会是一个很长的过程，希望尽量的获取更多的东西，文档格式尽量保持一致</p>]]>
    
    </summary>
    
      <category term="momotan" scheme="http://www.zphj1987.com/tags/momotan/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[关于ceph的rbd属性设置研究]]></title>
    <link href="http://www.zphj1987.com/2016/01/20/%E5%85%B3%E4%BA%8Eceph%E7%9A%84rbd%E5%B1%9E%E6%80%A7%E8%AE%BE%E7%BD%AE%E7%A0%94%E7%A9%B6/"/>
    <id>http://www.zphj1987.com/2016/01/20/关于ceph的rbd属性设置研究/</id>
    <published>2016-01-20T14:57:53.000Z</published>
    <updated>2016-01-22T16:39:08.000Z</updated>
    <content type="html"><![CDATA[<p>一个rbd在存储到后台以后,在后台是对象存储的，对象</p>
<p>[root@lab8106 rbdre]# rados -p rbd  listomapvals  rbd_directory<br>id_399a456aa808<br>value (6 bytes) :<br>0000 : 02 00 00 00 7a 70                               : ….zp</p>
<p>name_zp<br>value (16 bytes) :<br>0000 : 0c 00 00 00 33 39 39 61 34 35 36 61 61 38 30 38 : ….399a456aa808</p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- myweb -->
<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-3305801963238415" data-ad-slot="9673687470" data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>


]]></content>
    <summary type="html">
    <![CDATA[<p>一个rbd在存储到后台以后,在后台是对象存储的，对象</p>
<p>[root@lab8106 rbdre]# rados -p rbd  listomapvals  rbd_directory<br>id_399a456aa808<br>value (6 bytes) :]]>
    </summary>
    
  </entry>
  
  <entry>
    <title><![CDATA[ceph单机多mon的实现]]></title>
    <link href="http://www.zphj1987.com/2016/01/14/ceph%E5%8D%95%E6%9C%BA%E5%A4%9Amon%E7%9A%84%E5%AE%9E%E7%8E%B0/"/>
    <id>http://www.zphj1987.com/2016/01/14/ceph单机多mon的实现/</id>
    <published>2016-01-14T09:03:56.000Z</published>
    <updated>2016-01-14T09:11:03.572Z</updated>
    <content type="html"><![CDATA[<p>ceph默认情况下是以主机名来作为mon的识别的，所以这个情况下用部署工具是无法创建多个mon的，这个地方使用手动的方式可以很方便的创建多个mon</p>
<h3 id="1、创建mon的数据存储目录">1、创建mon的数据存储目录</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir /var/lib/ceph/mon/ceph-<span class="number">1</span></span><br></pre></td></tr></table></figure>
<h3 id="2、获取当前的monmap">2、获取当前的monmap</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph mon getmap -o /tmp/monmap</span><br></pre></td></tr></table></figure>
<h3 id="3、根据当前的monmap生成mon的数据">3、根据当前的monmap生成mon的数据</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph-mon -i <span class="number">1</span>  --mkfs --monmap /tmp/monmap</span><br></pre></td></tr></table></figure>
<h3 id="4、启动进程（后面指定端口）">4、启动进程（后面指定端口）</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph-mon -i <span class="number">1</span>  --public-addr  <span class="number">192.168</span>.<span class="number">8.106</span>:<span class="number">6791</span></span><br></pre></td></tr></table></figure>
<a id="more"></a>
<p>现在mon就加进去了</p>
<p>然后去写配置文件相关的信息即可，操作还是很便捷的，这个地方可以防止单mon的情况下的数据盘的损坏的情况，增加一点安全系数，当然最好是多主机的mon</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>ceph默认情况下是以主机名来作为mon的识别的，所以这个情况下用部署工具是无法创建多个mon的，这个地方使用手动的方式可以很方便的创建多个mon</p>
<h3 id="1、创建mon的数据存储目录">1、创建mon的数据存储目录</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">mkdir /var/lib/ceph/mon/ceph-<span class="number">1</span></span><br></pre></td></tr></table></figure>
<h3 id="2、获取当前的monmap">2、获取当前的monmap</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph mon getmap -o /tmp/monmap</span><br></pre></td></tr></table></figure>
<h3 id="3、根据当前的monmap生成mon的数据">3、根据当前的monmap生成mon的数据</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph-mon -i <span class="number">1</span>  --mkfs --monmap /tmp/monmap</span><br></pre></td></tr></table></figure>
<h3 id="4、启动进程（后面指定端口）">4、启动进程（后面指定端口）</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph-mon -i <span class="number">1</span>  --public-addr  <span class="number">192.168</span>.<span class="number">8.106</span>:<span class="number">6791</span></span><br></pre></td></tr></table></figure>]]>
    
    </summary>
    
      <category term="ceph" scheme="http://www.zphj1987.com/tags/ceph/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[ceph使用memdisk做journal]]></title>
    <link href="http://www.zphj1987.com/2016/01/14/ceph%E4%BD%BF%E7%94%A8memdisk%E5%81%9Ajournal/"/>
    <id>http://www.zphj1987.com/2016/01/14/ceph使用memdisk做journal/</id>
    <published>2016-01-14T02:00:59.000Z</published>
    <updated>2016-01-22T16:34:27.000Z</updated>
    <content type="html"><![CDATA[<p>记得在很久很久以前，ceph当时的版本是有提供使用内存做journal的配置的，当时是使用的tmpfs，但是现在的版本在搜资料的时候，发现关于这个的没怎么找到资料，邮件列表里面有人有提到怎么做，看了下大致的原理，然后还是自己来实践一次</p>
<h3 id="预备知识：">预备知识：</h3><p>首先需要知道的是什么是内存盘，内存盘就是划分了一个内存空间来当磁盘使用来进行加速的，这个在某些操作系统里面会把/tmp/分区挂载到tmpfs下，来达到加速的目的，这样就是重启后，会清空/tmp的内容，centos7 默认的分区方式也使用了tmpfs来加速，df -h可以看下那个tmpfs就是内存盘了</p>
<p>本文使用的不是tmpfs，这个是因为tmpfs不是我们常见意义上的那种文件系统，它不能格式化，ceph 在进行日志创建的时候会去检查journal 所在分区的 uuid， 而tmpfs在检测的时候 会返回一个全0的字符串，这个在校验的时候显示的无效的，所以也就部署起来有问题，下面开始介绍我的做法，这个里面做法很多，步骤也可以自己去变化，这里只是提供了我的一种思路</p>
<p>我使用的是ramdisk，关于怎么做ramdisk这个也研究了一下，因为篇幅有点长并且属于预备步骤，请参考我的另外一篇文章：</p>
<p><a href="http://www.zphj1987.com/2016/01/14/centos7%E4%B8%8B%E5%81%9A%E5%86%85%E5%AD%98%E7%9B%98%E7%9A%84%E6%96%B9%E6%B3%95/" title="centos7下做内存盘的方法" target="_blank" rel="external">centos7下做内存盘的方法</a></p>
<a id="more"></a>
<h3 id="测试环境：">测试环境：</h3><p>单机，四块SAS的OSD，日志为5G（内存盘大小为6G），副本 2， osd分组</p>
<p>说明：因为这里只去研究这个内存盘journal的实现，以及性能的差别，其他的组合方案需要自己去配置，所以单机的环境已经可以完成这个</p>
<h3 id="1、准备journal的内存盘">1、准备journal的内存盘</h3><h4 id="检查内存盘大小">检查内存盘大小</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@lab8106 ceph]<span class="comment"># fdisk -l /dev/ram0</span></span><br><span class="line"></span><br><span class="line">Disk /dev/ram0: <span class="number">6797</span> MB, <span class="number">6797721600</span> bytes, <span class="number">13276800</span> sectors</span><br><span class="line">Units = sectors of <span class="number">1</span> * <span class="number">512</span> = <span class="number">512</span> bytes</span><br><span class="line">Sector size (logical/physical): <span class="number">512</span> bytes / <span class="number">512</span> bytes</span><br><span class="line">I/O size (minimum/optimal): <span class="number">512</span> bytes / <span class="number">512</span> bytes</span><br></pre></td></tr></table></figure>
<p>我的大小为6G</p>
<h4 id="格式化内存盘，并且挂载">格式化内存盘，并且挂载</h4><h5 id="创建挂载目录（有多少osd建几个）">创建挂载目录（有多少osd建几个）</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@lab8106 ceph]<span class="comment"># mkdir -p /var/lib/ceph/mem/ceph-0</span></span><br></pre></td></tr></table></figure>
<h5 id="格式化memdisk(需要几个格式化几个)">格式化memdisk(需要几个格式化几个)</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@lab8106 ceph]<span class="comment"># mkfs.xfs /dev/ram0  -f</span></span><br></pre></td></tr></table></figure>
<h5 id="挂载内存盘">挂载内存盘</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@lab8106 ceph]<span class="comment"># mount /dev/ram0 /var/lib/ceph/mem/ceph-0/</span></span><br></pre></td></tr></table></figure>
<h5 id="挂载完了后的效果如下：">挂载完了后的效果如下：</h5><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@lab8106 ceph]<span class="comment"># df -h</span></span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">/dev/sda2        <span class="number">50</span>G  <span class="number">9.7</span>G   <span class="number">41</span>G  <span class="number">20</span>% /</span><br><span class="line">devtmpfs         <span class="number">24</span>G     <span class="number">0</span>   <span class="number">24</span>G   <span class="number">0</span>% /dev</span><br><span class="line">tmpfs            <span class="number">24</span>G     <span class="number">0</span>   <span class="number">24</span>G   <span class="number">0</span>% /dev/shm</span><br><span class="line">tmpfs            <span class="number">24</span>G   <span class="number">17</span>M   <span class="number">24</span>G   <span class="number">1</span>% /run</span><br><span class="line">tmpfs            <span class="number">24</span>G     <span class="number">0</span>   <span class="number">24</span>G   <span class="number">0</span>% /sys/fs/cgroup</span><br><span class="line">/dev/sda1       <span class="number">283</span>M   <span class="number">94</span>M  <span class="number">190</span>M  <span class="number">33</span>% /boot</span><br><span class="line">/dev/ram0       <span class="number">6.4</span>G   <span class="number">33</span>M  <span class="number">6.3</span>G   <span class="number">1</span>% /var/lib/ceph/mem/ceph-<span class="number">0</span></span><br><span class="line">/dev/ram1       <span class="number">6.4</span>G   <span class="number">33</span>M  <span class="number">6.3</span>G   <span class="number">1</span>% /var/lib/ceph/mem/ceph-<span class="number">1</span></span><br><span class="line">/dev/ram2       <span class="number">6.4</span>G   <span class="number">33</span>M  <span class="number">6.3</span>G   <span class="number">1</span>% /var/lib/ceph/mem/ceph-<span class="number">2</span></span><br><span class="line">/dev/ram3       <span class="number">6.4</span>G   <span class="number">33</span>M  <span class="number">6.3</span>G   <span class="number">1</span>% /var/lib/ceph/mem/ceph-<span class="number">3</span></span><br></pre></td></tr></table></figure>
<h3 id="2、准备ceph的环境">2、准备ceph的环境</h3><p>修改deploy的ceph.conf文件，在部署前修改好<br>单机环境添加下面的三个<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">osd_crush_chooseleaf_<span class="built_in">type</span> = <span class="number">0</span></span><br><span class="line">osd_pool_default_size = <span class="number">2</span></span><br><span class="line">osd_journal = /var/lib/ceph/mem/<span class="variable">$cluster</span>-<span class="variable">$id</span>/journal</span><br></pre></td></tr></table></figure></p>
<p>意思就不在这里介绍了</p>
<h4 id="创建mon">创建mon</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@lab8106 ceph]<span class="comment"># ceph-deploy mon create lab8106</span></span><br><span class="line">[root@lab8106 ceph]<span class="comment"># ceph-deploy gatherkeys lab8106</span></span><br></pre></td></tr></table></figure>
<h4 id="创建osd">创建osd</h4><p>[root@lab8106 ceph]# ceph-deploy osd prepare lab8106:/dev/sdb1:/var/lib/ceph/mem/ceph-0/journal<br>[root@lab8106 ceph]# ceph-deploy osd activate lab8106:/dev/sdb1<br>部署完这个检查下<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@lab8106 ceph]<span class="comment"># df -h</span></span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">……</span><br><span class="line">/dev/ram0       <span class="number">6.4</span>G  <span class="number">5.1</span>G  <span class="number">1.3</span>G  <span class="number">80</span>% /var/lib/ceph/mem/ceph-<span class="number">0</span></span><br><span class="line">/dev/ram1       <span class="number">6.4</span>G   <span class="number">33</span>M  <span class="number">6.3</span>G   <span class="number">1</span>% /var/lib/ceph/mem/ceph-<span class="number">1</span></span><br><span class="line">/dev/ram2       <span class="number">6.4</span>G   <span class="number">33</span>M  <span class="number">6.3</span>G   <span class="number">1</span>% /var/lib/ceph/mem/ceph-<span class="number">2</span></span><br><span class="line">/dev/ram3       <span class="number">6.4</span>G   <span class="number">33</span>M  <span class="number">6.3</span>G   <span class="number">1</span>% /var/lib/ceph/mem/ceph-<span class="number">3</span></span><br><span class="line">/dev/sdb1       <span class="number">280</span>G   <span class="number">34</span>M  <span class="number">280</span>G   <span class="number">1</span>% /var/lib/ceph/osd/ceph-<span class="number">0</span></span><br></pre></td></tr></table></figure></p>
<p>可以看到内存盘分区内已经生成可一个5G的journal文件<br><figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line">[root<span class="annotation">@lab</span>8106 ceph]# ll <span class="regexp">/var/</span>lib<span class="regexp">/ceph/</span>osd/ceph-<span class="number">0</span></span><br><span class="line">total <span class="number">40</span></span><br><span class="line">……</span><br><span class="line">lrwxrwxrwx  <span class="number">1</span> root root   <span class="number">32</span> Jan <span class="number">14</span> <span class="number">10</span>:<span class="number">28</span> journal -&gt; <span class="regexp">/var/</span>lib<span class="regexp">/ceph/</span>mem<span class="regexp">/ceph-0/</span>journal</span><br></pre></td></tr></table></figure></p>
<p>可以看到osd分区的也是链接到了内存盘，环境没问题</p>
<h4 id="继续部署生效的三个osd">继续部署生效的三个osd</h4><p>部署完再次检查环境<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@lab8106 ceph]<span class="comment"># df -h|grep ceph</span></span><br><span class="line">/dev/ram0       <span class="number">6.4</span>G  <span class="number">5.1</span>G  <span class="number">1.3</span>G  <span class="number">80</span>% /var/lib/ceph/mem/ceph-<span class="number">0</span></span><br><span class="line">/dev/ram1       <span class="number">6.4</span>G  <span class="number">5.1</span>G  <span class="number">1.3</span>G  <span class="number">80</span>% /var/lib/ceph/mem/ceph-<span class="number">1</span></span><br><span class="line">/dev/ram2       <span class="number">6.4</span>G  <span class="number">5.1</span>G  <span class="number">1.3</span>G  <span class="number">80</span>% /var/lib/ceph/mem/ceph-<span class="number">2</span></span><br><span class="line">/dev/ram3       <span class="number">6.4</span>G  <span class="number">5.1</span>G  <span class="number">1.3</span>G  <span class="number">80</span>% /var/lib/ceph/mem/ceph-<span class="number">3</span></span><br><span class="line">/dev/sdb1       <span class="number">280</span>G   <span class="number">34</span>M  <span class="number">280</span>G   <span class="number">1</span>% /var/lib/ceph/osd/ceph-<span class="number">0</span></span><br><span class="line">/dev/sdc1       <span class="number">280</span>G   <span class="number">34</span>M  <span class="number">280</span>G   <span class="number">1</span>% /var/lib/ceph/osd/ceph-<span class="number">1</span></span><br><span class="line">/dev/sdd1       <span class="number">280</span>G   <span class="number">34</span>M  <span class="number">280</span>G   <span class="number">1</span>% /var/lib/ceph/osd/ceph-<span class="number">2</span></span><br><span class="line">/dev/sde1       <span class="number">280</span>G   <span class="number">33</span>M  <span class="number">280</span>G   <span class="number">1</span>% /var/lib/ceph/osd/ceph-<span class="number">3</span></span><br></pre></td></tr></table></figure></p>
<p>都挂载正确<br>检查集群的状态<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@lab8106 ceph]<span class="comment"># ceph -s</span></span><br><span class="line">    cluster <span class="number">68735617</span>-<span class="number">2</span>d30-<span class="number">4</span>a81-<span class="number">9865</span>-aeab3ea85e6e</span><br><span class="line">     health HEALTH_OK</span><br><span class="line">     monmap e1: <span class="number">1</span> mons at &#123;lab8106=<span class="number">192.168</span>.<span class="number">8.106</span>:<span class="number">6789</span>/<span class="number">0</span>&#125;</span><br><span class="line">            election epoch <span class="number">2</span>, quorum <span class="number">0</span> lab8106</span><br><span class="line">     osdmap e21: <span class="number">4</span> osds: <span class="number">4</span> up, <span class="number">4</span> <span class="keyword">in</span></span><br><span class="line">      pgmap v35: <span class="number">192</span> pgs, <span class="number">1</span> pools, <span class="number">0</span> bytes data, <span class="number">0</span> objects</span><br><span class="line">            <span class="number">136</span> MB used, <span class="number">1116</span> GB / <span class="number">1117</span> GB avail</span><br><span class="line">                 <span class="number">192</span> active+clean</span><br></pre></td></tr></table></figure></p>
<p>环境部署完毕</p>
<h3 id="开始测试">开始测试</h3><p>测试一：采用内存盘journal的方式<br>使用radosbench进行测试（采取默认的写，并且不删除的测试，尽量把内存写满，未进行任何调优）<br><figure class="highlight groovy"><table><tr><td class="code"><pre><span class="line">[root<span class="annotation">@lab</span>8106 ceph]# rados bench -p rbd <span class="number">120</span> write --no-cleanup --run-name testmemdisk</span><br><span class="line">Total time <span class="string">run:</span>         <span class="number">120.568031</span></span><br><span class="line">Total writes <span class="string">made:</span>      <span class="number">5857</span></span><br><span class="line">Write <span class="string">size:</span>             <span class="number">4194304</span></span><br><span class="line">Bandwidth (MB/sec):     <span class="number">194.314</span> </span><br><span class="line"></span><br><span class="line">Stddev <span class="string">Bandwidth:</span>       <span class="number">144.18</span></span><br><span class="line">Max bandwidth (MB/sec): <span class="number">504</span></span><br><span class="line">Min bandwidth (MB/sec): <span class="number">0</span></span><br><span class="line">Average <span class="string">Latency:</span>        <span class="number">0.329322</span></span><br><span class="line">Stddev <span class="string">Latency:</span>         <span class="number">0.48777</span></span><br><span class="line">Max <span class="string">latency:</span>            <span class="number">3.01612</span></span><br><span class="line">Min <span class="string">latency:</span>            <span class="number">0.0377235</span></span><br></pre></td></tr></table></figure></p>
<p>测试二：采用默认的磁盘journal的方式，环境恢复要原始的情况<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@lab8106 ceph]<span class="comment"># rados bench -p rbd 120 write --no-cleanup --run-name testmemdisk</span></span><br><span class="line">Total time run:         <span class="number">120.613851</span></span><br><span class="line">Total writes made:      <span class="number">3404</span></span><br><span class="line">Write size:             <span class="number">4194304</span></span><br><span class="line">Bandwidth (MB/sec):     <span class="number">112.889</span> </span><br><span class="line"></span><br><span class="line">Stddev Bandwidth:       <span class="number">26.3641</span></span><br><span class="line">Max bandwidth (MB/sec): <span class="number">160</span></span><br><span class="line">M<span class="keyword">in</span> bandwidth (MB/sec): <span class="number">0</span></span><br><span class="line">Average Latency:        <span class="number">0.566656</span></span><br><span class="line">Stddev Latency:         <span class="number">0.305038</span></span><br><span class="line">Max latency:            <span class="number">2.00623</span></span><br><span class="line">M<span class="keyword">in</span> latency:            <span class="number">0.105026</span></span><br></pre></td></tr></table></figure></p>
<p>测试的结果如上，上表格也许看的更直观，正好之前在找一个表格插件，现在用用</p>
<h3 id="内存盘journal与磁盘journal性能对比">内存盘journal与磁盘journal性能对比</h3><p></p><p><link rel="stylesheet" href="http://7xo9we.com1.z0.glb.clouddn.com/compareninja%2Fskin.css" type="text/css"></p><div id="tableWrapper" style="width: 100%; "><table id="vsTable"><tbody><tr><td class="cat title" style="width: 20%; "></td><td class="title" style="width: 40%; "><div class="">内存盘journal</div></td><td class="title" style="width: 40%; "><div class="">磁盘journal</div></td></tr><tr class="second"><td class="cat" style="width: 20%; "><div class="">测试时间(s)</div></td><td style="width: 40%; "><div class="">120.568031</div></td><td style="width: 40%; "><div class="">120.613851</div></td></tr><tr><td class="cat" style="width: 20%; "><div class="">写数据块数</div></td><td style="width: 40%; "><div class="">5857</div></td><td style="width: 40%; "><div class="">3404</div></td></tr><tr><td class="cat" style="width: 20%; "><div class="">总共写入数据(MB)</div></td><td style="width: 40%; "><div class="">23428</div></td><td style="width: 40%; "><div class="">13616</div></td></tr><tr><td class="cat" style="width: 20%; "><div class="">数据块大小</div></td><td style="width: 40%; "><div class="">4194304</div></td><td style="width: 40%; "><div class="">4194304</div></td></tr><tr class="second"><td class="cat" style="width: 20%; "><div class="">写带宽(MB/sec)</div></td><td style="width: 40%; "><div class="">194.314</div></td><td style="width: 40%; "><div class="">112.889</div></td></tr><tr><td class="cat" style="width: 20%; "><div class="">带宽标准偏差</div></td><td style="width: 40%; "><div class="">144.18</div></td><td style="width: 40%; "><div class="">26.3641</div></td></tr><tr class="second"><td class="cat" style="width: 20%; "><div class="">最大带宽(MB/sec)</div></td><td style="width: 40%; "><div class="">504</div></td><td style="width: 40%; "><div class="">160</div></td></tr><tr><td class="cat" style="width: 20%; "><div class="">平均延时</div></td><td style="width: 40%; "><div class="">0.32932</div></td><td style="width: 40%; "><div class="">0.566656</div></td></tr><tr class="second"><td class="cat" style="width: 20%; "><div class="">延时偏差</div></td><td style="width: 40%; "><div class="">0.48777</div></td><td style="width: 40%; "><div class="">0.305038</div></td></tr><tr class="second"><td class="cat" style="width: 20%; "><div class="">最大延时</div></td><td style="width: 40%; "><div class="">3.01612</div></td><td style="width: 40%; "><div class="">2.00623</div></td></tr><tr class="second"><td class="cat" style="width: 20%; "><div class="">最小延时</div></td><td style="width: 40%; "><div class="">0.0377235</div></td><td style="width: 40%; "><div class="">0.105026</div></td></tr></tbody></table></div><p></p>
<p>可以看到相关数据，光写带宽就提升了接近一倍，这个是因为，在磁盘journal情况下，写入journal的同时还有filestore的数据写入，相当于同时有两个写入在磁盘上，磁盘的性能自然只有一半了</p>
<p>以上就是关于journal的内存盘实现，这里面还会面临着其他的问题</p>
<ul>
<li>机器内存的占用问题</li>
<li>断电后的处理</li>
<li>同时断电是否会搞坏pg状态</li>
<li>搞坏的情况是否能恢复</li>
</ul>
<p>如果解决了这些问题，这个不失为一种性能提升的方案，毕竟内存的成本和速度是ssd的磁盘和单独磁盘journal不能比的，journal本身也是一种循环的写入的空间</p>
<hr>
<p>教程的方式暂时停止了，毕竟推广这块还是有问题<br>结尾还是来个支持的链接，如果你觉得文章写得好，欢迎打赏，如果有新文章我会第一时间推送给支持我的朋友</p>
<p><img src="http://7xo9we.com1.z0.glb.clouddn.com/zhifubao.png" alt=""></p>
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- myweb -->
<ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-3305801963238415" data-ad-slot="9673687470" data-ad-format="auto"></ins>
<script>
(adsbygoogle = window.adsbygoogle || []).push({});
</script>]]></content>
    <summary type="html">
    <![CDATA[<p>记得在很久很久以前，ceph当时的版本是有提供使用内存做journal的配置的，当时是使用的tmpfs，但是现在的版本在搜资料的时候，发现关于这个的没怎么找到资料，邮件列表里面有人有提到怎么做，看了下大致的原理，然后还是自己来实践一次</p>
<h3 id="预备知识：">预备知识：</h3><p>首先需要知道的是什么是内存盘，内存盘就是划分了一个内存空间来当磁盘使用来进行加速的，这个在某些操作系统里面会把/tmp/分区挂载到tmpfs下，来达到加速的目的，这样就是重启后，会清空/tmp的内容，centos7 默认的分区方式也使用了tmpfs来加速，df -h可以看下那个tmpfs就是内存盘了</p>
<p>本文使用的不是tmpfs，这个是因为tmpfs不是我们常见意义上的那种文件系统，它不能格式化，ceph 在进行日志创建的时候会去检查journal 所在分区的 uuid， 而tmpfs在检测的时候 会返回一个全0的字符串，这个在校验的时候显示的无效的，所以也就部署起来有问题，下面开始介绍我的做法，这个里面做法很多，步骤也可以自己去变化，这里只是提供了我的一种思路</p>
<p>我使用的是ramdisk，关于怎么做ramdisk这个也研究了一下，因为篇幅有点长并且属于预备步骤，请参考我的另外一篇文章：</p>
<p><a href="http://www.zphj1987.com/2016/01/14/centos7%E4%B8%8B%E5%81%9A%E5%86%85%E5%AD%98%E7%9B%98%E7%9A%84%E6%96%B9%E6%B3%95/" title="centos7下做内存盘的方法">centos7下做内存盘的方法</a></p>]]>
    
    </summary>
    
      <category term="ceph" scheme="http://www.zphj1987.com/tags/ceph/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[centos7下做内存盘的方法]]></title>
    <link href="http://www.zphj1987.com/2016/01/14/centos7%E4%B8%8B%E5%81%9A%E5%86%85%E5%AD%98%E7%9B%98%E7%9A%84%E6%96%B9%E6%B3%95/"/>
    <id>http://www.zphj1987.com/2016/01/14/centos7下做内存盘的方法/</id>
    <published>2016-01-14T01:07:28.000Z</published>
    <updated>2016-01-14T01:58:56.316Z</updated>
    <content type="html"><![CDATA[<p>在找这个资料的时候，基本没几个能用的或者过时了的，或者是换了概念，做的不是需要的那种盘，只有少数文章有提到关键部分应该怎么去操作，现在还是自己总结一下</p>
<h3 id="内存盘tmpfs和ramdisk的区别">内存盘tmpfs和ramdisk的区别</h3><p>这个在网上的很多资料里面都有提到，很多文章去写怎么做ramdisk的时候，都是去做的tmpfs，两者虽然都是使用的内存来存储东西，但是是完全有区别的</p>
<ul>
<li>tmpfs这个只需要mount挂载就可以分配一个目录使用内存了，只是一个目录</li>
<li>ramdisk这个是真的分配一个空间，这个分区是可以格式化的（这个格式化是关键）</li>
<li>tmpfs卸载再挂载数据会消失，randisk卸载再挂载数据还在</li>
<li>二者共同点是，系统重启后，里面的东西会消失</li>
</ul>
<blockquote>
<p>本文章主要是讲怎么去做ramdisk</p>
</blockquote>
<a id="more"></a>
<p>ramdisk是依赖于内核模块brd的，首先可以查看下这个模块的信息<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@lab8106 src]<span class="comment"># modinfo brd</span></span><br><span class="line">filename:       /lib/modules/<span class="number">3.10</span>.<span class="number">0</span>-<span class="number">229</span>.el7.x86_64/kernel/drivers/block/brd.ko</span><br><span class="line"><span class="built_in">alias</span>:          rd</span><br><span class="line"><span class="built_in">alias</span>:          block-major-<span class="number">1</span>-*</span><br><span class="line">license:        GPL</span><br><span class="line">rhelversion:    <span class="number">7.1</span></span><br><span class="line">srcversion:     F38BA5B60FC8B94786C7907</span><br><span class="line">depends:        </span><br><span class="line">intree:         Y</span><br><span class="line">vermagic:       <span class="number">3.10</span>.<span class="number">0</span> SMP mod_unload modversions </span><br><span class="line">parm:           rd_nr:Maximum number of brd devices (int)</span><br><span class="line">parm:           rd_size:Size of each RAM disk <span class="keyword">in</span> kbytes. (int)</span><br><span class="line">parm:           max_part:Maximum number of partitions per RAM disk (int)</span><br></pre></td></tr></table></figure></p>
<p>默认是不加载的，需要加载这个模块<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@lab8106 src]<span class="comment"># modprobe brd</span></span><br></pre></td></tr></table></figure></p>
<p>加载模块后就会生成下面的的盘符路径，这个就是内存盘<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@lab8106 src]<span class="comment"># ll /dev/ram*</span></span><br><span class="line">brw-rw---- <span class="number">1</span> root disk <span class="number">1</span>, <span class="number">0</span> Jan <span class="number">14</span> <span class="number">00</span>:<span class="number">43</span> /dev/ram0</span><br><span class="line">brw-rw---- <span class="number">1</span> root disk <span class="number">1</span>, <span class="number">1</span> Jan <span class="number">14</span> <span class="number">00</span>:<span class="number">43</span> /dev/ram1</span><br><span class="line">brw-rw---- <span class="number">1</span> root disk <span class="number">1</span>, <span class="number">2</span> Jan <span class="number">14</span> <span class="number">00</span>:<span class="number">42</span> /dev/ram2</span><br><span class="line">brw-rw---- <span class="number">1</span> root disk <span class="number">1</span>, <span class="number">3</span> Jan <span class="number">14</span> <span class="number">00</span>:<span class="number">42</span> /dev/ram3</span><br></pre></td></tr></table></figure></p>
<p>这个的默认大小是16M，设备的数目是16个，这个显然是不符合我们的需求的</p>
<p>这个个数信息和大小信息是写在内核模块里面的,这个目前还找到办法在外面修改的地方，现在通过修改内核模块的方式来达到修改的目的</p>
<h3 id="1、获取内核源码">1、获取内核源码</h3><p> CentOS-7-x86_64-1503-01版本的内核是3.10.0-229.el7.x86_64，这个最好是使用的对应版本的内核代码，这样不会出现其他的问题，下载该distribution版本的内核源码，拷贝到根目录：<br><a href="http://vault.centos.org/7.1.1503/updates/Source/SPackages/kernel-3.10.0-229.1.2.el7.src.rpm" target="_blank" rel="external">http://vault.centos.org/7.1.1503/updates/Source/SPackages/kernel-3.10.0-229.1.2.el7.src.rpm</a></p>
<h4 id="安装该源码包">安装该源码包</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@lab8106 ~]<span class="comment"># rpm -i kernel-3.10.0-229.1.2.el7.src.rpm</span></span><br></pre></td></tr></table></figure>
<p>安装完了以后，这个rpm包里面的源码会被放在 ~/rpmbuild/SOURCES/ 这个目录内，源码文件是linux-3.10.0-229.1.2.el7.tar.xz </p>
<h3 id="2、编译内核源码">2、编译内核源码</h3><p>将linux-3.10.0-229.1.2.el7.tar.xz 文件拷贝到目录  /usr/src/zp 下<br>这个是你自己定义一个编译的目录</p>
<h3 id="3、解压内核源码">3、解压内核源码</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@lab8106 zp]<span class="comment"># tar -xvf linux-3.10.0-229.1.2.el7.tar.xz</span></span><br><span class="line">[root@lab8106 zp]<span class="comment"># cd linux-3.10.0-229.1.2.el7/</span></span><br></pre></td></tr></table></figure>
<h3 id="4、清理编译环境的状态，如果你是下载的内核源码，而且是第一次编译，就没有必要执行这一步操作">4、清理编译环境的状态，如果你是下载的内核源码，而且是第一次编译，就没有必要执行这一步操作</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@lab8106 ~]<span class="comment"># make mrproper</span></span><br></pre></td></tr></table></figure>
<h4 id="将已存在的-/-config文件内容，作为新版本内核的默认值">将已存在的./.config文件内容，作为新版本内核的默认值</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@lab8106 ~]<span class="comment"># make oldconfig</span></span><br></pre></td></tr></table></figure>
<h4 id="配置内核的参数，修改ramdisk的相关属性">配置内核的参数，修改ramdisk的相关属性</h4><p>在内核配置菜单中配置ramdisk块驱动模块的个数和大小，并保存退出<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">Device Drivers </span><br><span class="line">       |--&gt;Block devices </span><br><span class="line">                  |--&gt;  [M]RAM block device support </span><br><span class="line">                           (xx) Default number of RAM disks </span><br><span class="line">                           (xx) Default RAM disk size(kbytes)</span><br></pre></td></tr></table></figure></p>
<p>如果内存够大，可以修改大点，注意这个地方是每个内存盘的大小</p>
<h3 id="5、编译内核模块">5、编译内核模块</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@lab8106 zp]<span class="comment"># make modules -j8</span></span><br></pre></td></tr></table></figure>
<h4 id="编译后的Ramdisk模块的存放位置">编译后的Ramdisk模块的存放位置</h4><figure class="highlight gradle"><table><tr><td class="code"><pre><span class="line"><span class="regexp">/usr/</span>src<span class="regexp">/zp/</span>linux-<span class="number">3.10</span>.<span class="number">0</span>-<span class="number">229.1</span>.<span class="number">2</span>.el7<span class="regexp">/drivers/</span>block<span class="regexp">/brd.ko</span></span><br></pre></td></tr></table></figure>
<h3 id="6、安装新的brd-ko模块">6、安装新的brd.ko模块</h3><p>将旧的brd.ko模块从内核中移除。<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@lab8106 zp]<span class="comment"># rmmod brd</span></span><br></pre></td></tr></table></figure></p>
<p>将新的brd.ko模块拷贝到Centos7系统的 如下目录/lib/modules/3.10.0-229.el7.x86_64/kernel/drivers/block/，<br>覆盖原来的ramDisk模块brd.ko</p>
<h3 id="7、更新内核模块依赖">7、更新内核模块依赖</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@lab8106 zp]<span class="comment"># depmod -a</span></span><br></pre></td></tr></table></figure>
<h3 id="8、重新挂载内核模块。_如果加载的时候报错就强制加载_modprobe_-f_brd">8、重新挂载内核模块。 如果加载的时候报错就强制加载  <code>modprobe -f brd</code></h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@lab8106 zp]<span class="comment"># modprobe brd</span></span><br></pre></td></tr></table></figure>
<h3 id="9、检查是否生成了">9、检查是否生成了</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@lab8106 zp]<span class="comment"># ls /dev/ram*</span></span><br></pre></td></tr></table></figure>
<p>然后就可以使用/dev/ram*这个设备了，当磁盘一样使用</p>
<p>我的为测试环境，内存不是那么大，就是5G内存盘，4个，做对比测试，ceph默认的5G的journal，这个内存就稍微给大那么一点点6G，防止单位换算的原因造成空间不够，需要重来</p>
<hr>
<p>这篇文章基本都是参考了：<br><a href="http://my.oschina.net/u/658505/blog/544547?fromerr=wWO13oYJ" target="_blank" rel="external">http://my.oschina.net/u/658505/blog/544547?fromerr=wWO13oYJ</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>在找这个资料的时候，基本没几个能用的或者过时了的，或者是换了概念，做的不是需要的那种盘，只有少数文章有提到关键部分应该怎么去操作，现在还是自己总结一下</p>
<h3 id="内存盘tmpfs和ramdisk的区别">内存盘tmpfs和ramdisk的区别</h3><p>这个在网上的很多资料里面都有提到，很多文章去写怎么做ramdisk的时候，都是去做的tmpfs，两者虽然都是使用的内存来存储东西，但是是完全有区别的</p>
<ul>
<li>tmpfs这个只需要mount挂载就可以分配一个目录使用内存了，只是一个目录</li>
<li>ramdisk这个是真的分配一个空间，这个分区是可以格式化的（这个格式化是关键）</li>
<li>tmpfs卸载再挂载数据会消失，randisk卸载再挂载数据还在</li>
<li>二者共同点是，系统重启后，里面的东西会消失</li>
</ul>
<blockquote>
<p>本文章主要是讲怎么去做ramdisk</p>
</blockquote>]]>
    
    </summary>
    
      <category term="linux" scheme="http://www.zphj1987.com/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[删除osd的正确方式]]></title>
    <link href="http://www.zphj1987.com/2016/01/12/%E5%88%A0%E9%99%A4osd%E7%9A%84%E6%AD%A3%E7%A1%AE%E6%96%B9%E5%BC%8F/"/>
    <id>http://www.zphj1987.com/2016/01/12/删除osd的正确方式/</id>
    <published>2016-01-12T02:14:39.000Z</published>
    <updated>2016-01-13T03:29:12.847Z</updated>
    <content type="html"><![CDATA[<p>在ceph的集群当中关于节点的替换的问题，一直按照以前的方式进行的处理，处理的步骤如下：</p>
<ol>
<li>停止osd进程<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/etc/init.d/ceph stop osd.<span class="number">0</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>这一步是停止osd的进程，让其他的osd知道这个节点不提供服务了</p>
<ol>
<li>将节点状态标记为out<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph osd out osd.<span class="number">0</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>这个一步是告诉mon，这个节点已经不能服务了，需要在其他的osd上进行数据的恢复了</p>
<ol>
<li>从crush中移除节点<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph osd crush remove osd.<span class="number">0</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>从crush中删除是告诉集群这个点回不来了，完全从集群的分布当中剔除掉，让集群的crush进行一次重新计算，之前节点还占着这个crush weight，会影响到当前主机的host crush weight </p>
<ol>
<li>删除节点<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph osd rm osd.<span class="number">0</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>这个是从集群里面删除这个节点的记录</p>
<ol>
<li>删除节点认证（不删除编号会占住）<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph auth del osd.<span class="number">0</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>这个是从认证当中去删除这个节点的信息<br><a id="more"></a></p>
<p>这个一直是我处理故障的节点osd的方式，其实这个会触发两次迁移，一次是在节点osd以后，一个是在crush remove以后，两次迁移对于集群来说是不好的，其实是调整步骤是可以避免二次迁移的</p>
<h3 id="新的处理方式">新的处理方式</h3><ol>
<li>调整osd的crush weight <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph osd crush reweight osd.<span class="number">0</span> <span class="number">0.1</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>说明：这个地方如果想慢慢的调整就分几次将crush 的weight 减低到0 ，这个过程实际上是让数据不分布在这个节点上，让数据慢慢的分布到其他节点上，直到最终为没有分布在这个osd，并且迁移完成<br>这个地方不光调整了osd 的crush weight ，实际上同时调整了host 的 weight ，这样会调整集群的整体的crush 分布，在osd 的crush 为0 后， 再对这个osd的任何删除相关操作都不会影响到集群的数据的分布</p>
<ol>
<li>停止osd进程<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/etc/init.d/ceph stop osd.<span class="number">0</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>停止到osd的进程，这个是通知集群这个osd进程不在了，不提供服务了，因为本身没权重，就不会影响到整体的分布，也就没有迁移</p>
<ol>
<li>将节点状态标记为out<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph osd out osd.<span class="number">0</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>停止到osd的进程，这个是通知集群这个osd不再映射数据了，不提供服务了，因为本身没权重，就不会影响到整体的分布，也就没有迁移</p>
<ol>
<li>从crush中移除节点<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph osd crush remove osd.<span class="number">0</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>这个是从crush中删除，因为已经是0了  所以没影响主机的权重，也就没有迁移了</p>
<ol>
<li>删除节点<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph osd rm osd.<span class="number">0</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>这个是从集群里面删除这个节点的记录</p>
<ol>
<li>删除节点认证（不删除编号会占住）<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph auth del osd.<span class="number">0</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>这个是从认证当中去删除这个节点的信息</p>
<p>经过验证，第二种方式只触发了一次迁移，虽然只是一个步骤先后上的调整，对于生产环境的的集群来说，迁移的量要少了一次，实际生产环境当中节点是有自动out的功能，这个可以考虑自己去控制，只是监控的密度需要加大，毕竟这个是一个需要监控的集群，完全让其自己处理数据的迁移是不可能的，带来的故障只会更多</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>在ceph的集群当中关于节点的替换的问题，一直按照以前的方式进行的处理，处理的步骤如下：</p>
<ol>
<li>停止osd进程<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/etc/init.d/ceph stop osd.<span class="number">0</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>这一步是停止osd的进程，让其他的osd知道这个节点不提供服务了</p>
<ol>
<li>将节点状态标记为out<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph osd out osd.<span class="number">0</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>这个一步是告诉mon，这个节点已经不能服务了，需要在其他的osd上进行数据的恢复了</p>
<ol>
<li>从crush中移除节点<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph osd crush remove osd.<span class="number">0</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>从crush中删除是告诉集群这个点回不来了，完全从集群的分布当中剔除掉，让集群的crush进行一次重新计算，之前节点还占着这个crush weight，会影响到当前主机的host crush weight </p>
<ol>
<li>删除节点<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph osd rm osd.<span class="number">0</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>这个是从集群里面删除这个节点的记录</p>
<ol>
<li>删除节点认证（不删除编号会占住）<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph auth del osd.<span class="number">0</span></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>这个是从认证当中去删除这个节点的信息<br>]]>
    
    </summary>
    
      <category term="ceph" scheme="http://www.zphj1987.com/tags/ceph/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[ceph写osd的配置文件/etc/ceph/ceph.conf]]></title>
    <link href="http://www.zphj1987.com/2016/01/11/ceph%E5%86%99osd%E7%9A%84%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-etc-ceph-ceph-conf/"/>
    <id>http://www.zphj1987.com/2016/01/11/ceph写osd的配置文件-etc-ceph-ceph-conf/</id>
    <published>2016-01-11T08:38:25.000Z</published>
    <updated>2016-01-11T08:50:49.321Z</updated>
    <content type="html"><![CDATA[<p>ceph在部署过程中是先进行部署，再去写配置文件的，而一些新手在部署完了后，并没有写配置文件，在重启服务器后，因为挂载点没有挂载，所以服务无法启动，所以需要写好配置文件<br>还有一种情况是集群有几百个osd，在新加入或者修改的时候，再去进行变更配置文件就是一个很麻烦的事情，所以写配置文件这个如果脚本来处理，就可以节约很多时间，所以写了一个脚本如下，这个地方如果熟悉python的可以用python写，我这个是自己使用，并且使用的频率不会太高，因此，怎么方便怎么来</p>
<p>脚本里面用了一个二进制文件是解析json用的，这个拷贝到运行的机器上就可以了</p>
<p>解析的二进制文件在这里下载：<br><a href="http://stedolan.github.io/jq/" target="_blank" rel="external">http://stedolan.github.io/jq/</a></p>
<p>备用下载地址：<br><a href="http://pan.baidu.com/s/1pKgefmr" target="_blank" rel="external">http://pan.baidu.com/s/1pKgefmr</a></p>
<p>下载后拷贝到linux机器的/sbin/下面，为了方便重命名为 /sbin/jq</p>
<p>后面的输出可以方便的修改，原理是获取当前的osd状态，然后去osd上获取信息</p>
<a id="more"></a>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="shebang">#! /bin/sh</span></span><br><span class="line"><span class="comment">#注意要配合js使用http://stedolan.github.io/jq/</span></span><br><span class="line"><span class="keyword">for</span> osd <span class="keyword">in</span> `ceph osd dump |awk  <span class="string">'/^osd/ &#123;print $1&#125;'</span>|cut <span class="operator">-d</span> . <span class="operator">-f</span> <span class="number">2</span>`</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line"><span class="comment">#获取主机名</span></span><br><span class="line">osdhost=`ceph osd find <span class="variable">$osd</span> |jq <span class="string">'.crush_location'</span> |jq <span class="string">'.host'</span>|cut <span class="operator">-d</span> \<span class="string">" -f 2`</span><br><span class="line">#获取主机的ip</span><br><span class="line">osdip=`ceph osd find <span class="variable">$osd</span> |jq '.ip' |cut -d : -f 1|cut -d \" -f 2`</span><br><span class="line">#获取主机的磁盘</span><br><span class="line">osddisk=`ssh <span class="variable">$osdip</span> findmnt /var/lib/ceph/osd/ceph-<span class="variable">$osd</span>|awk '&#123;print <span class="variable">$2</span>&#125;'|tail -n 1`</span><br><span class="line">#获取主机的uuid</span><br><span class="line">uuid=`ssh <span class="variable">$osdip</span> blkid <span class="variable">$osddisk</span>|cut -d : -f 2|cut -d "</span> <span class="string">" -f 2|cut -d \" -f 2`</span><br><span class="line">#写入文件</span><br><span class="line">echo "</span>osd.<span class="variable">$osd</span>.host = <span class="variable">$osdhost</span><span class="string">" &gt;&gt; mydiskinfo</span><br><span class="line">echo "</span>osd.<span class="variable">$osd</span>.uuid = <span class="variable">$uuid</span>  <span class="string">" &gt;&gt; mydiskinfo</span><br><span class="line">echo "</span>osd.<span class="variable">$osd</span>.devs = <span class="variable">$osddisk</span><span class="string">" &gt;&gt; mydiskinfo</span><br><span class="line">done</span></span><br></pre></td></tr></table></figure>]]></content>
    <summary type="html">
    <![CDATA[<p>ceph在部署过程中是先进行部署，再去写配置文件的，而一些新手在部署完了后，并没有写配置文件，在重启服务器后，因为挂载点没有挂载，所以服务无法启动，所以需要写好配置文件<br>还有一种情况是集群有几百个osd，在新加入或者修改的时候，再去进行变更配置文件就是一个很麻烦的事情，所以写配置文件这个如果脚本来处理，就可以节约很多时间，所以写了一个脚本如下，这个地方如果熟悉python的可以用python写，我这个是自己使用，并且使用的频率不会太高，因此，怎么方便怎么来</p>
<p>脚本里面用了一个二进制文件是解析json用的，这个拷贝到运行的机器上就可以了</p>
<p>解析的二进制文件在这里下载：<br><a href="http://stedolan.github.io/jq/">http://stedolan.github.io/jq/</a></p>
<p>备用下载地址：<br><a href="http://pan.baidu.com/s/1pKgefmr">http://pan.baidu.com/s/1pKgefmr</a></p>
<p>下载后拷贝到linux机器的/sbin/下面，为了方便重命名为 /sbin/jq</p>
<p>后面的输出可以方便的修改，原理是获取当前的osd状态，然后去osd上获取信息</p>]]>
    
    </summary>
    
      <category term="ceph" scheme="http://www.zphj1987.com/tags/ceph/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[centos6安装calamari]]></title>
    <link href="http://www.zphj1987.com/2015/12/19/centos6%E5%AE%89%E8%A3%85calamari/"/>
    <id>http://www.zphj1987.com/2015/12/19/centos6安装calamari/</id>
    <published>2015-12-19T14:07:01.000Z</published>
    <updated>2015-12-21T15:59:16.615Z</updated>
    <content type="html"><![CDATA[<h3 id="一、安装操作系统">一、安装操作系统</h3><p>首先安装操作系统centos6,安装过程选择的是base server，这个不相同不要紧，出现缺少包的时候去iso找出来安装就可以了</p>
<h3 id="二、calamari的简单介绍">二、calamari的简单介绍</h3><p>首先简单的介绍下calamari的这个软件系统的组成，主要是calamari-server,romana，salt-minion，salt-server，diamond，</p>
<p>这些模块各自的作用：</p>
<ul>
<li>calamari-server这个是提供一个与集群进行交互，并且自己封装了一个自己的API，做集中管理的地方，这个只需要在集群当中的某一台机器上安装，也可以独立安装</li>
<li>romana就是原来的calamari-client，这个叫client,其实是一个web的界面，这个叫calamari-web更好，现在已经更名为romana，这个也是只需要在集群当中的某一台机器上安装，也可以独立安装，这个需要跟calamari-server安装在一台机器上</li>
<li>salt-server是一个管理的工具，可以批量的管理其他的机器，可以对安装了salt-minion的机器进行管理，在集群当中，这个也是跟calamari-server安装在一起的</li>
<li>salt-minion是安装在集群的所有节点上的，这个是接收salt-server的指令对集群的机器进行操作，并且反馈一些信息到salt-server上</li>
<li>diamond这个是系统的监控信息的收集控件，提供集群的硬件信息的监控和集群的信息的监控，数据是发送到romana的机器上的，是由romana上的carbon来收取数据并存储到机器当中的数据库当中的</li>
</ul>
<a id="more"></a>
<p>所以总结下来安装的方式是:</p>
<table>
<thead>
<tr>
<th style="text-align:center">节点情况</th>
<th style="text-align:center">需要安装软件</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">单独一台非集群节点装calmari-server</td>
<td style="text-align:center">calamri-server romana salt-master salt-minion</td>
</tr>
<tr>
<td style="text-align:center">集群节点</td>
<td style="text-align:center">salt-minion diamond</td>
</tr>
</tbody>
</table>
<p>注意：<br>如果calamri-server选择安装在集群内节点，那么这台机器就安装 calamri-server romana salt-master salt-minion diamond </p>
<h3 id="三、软件安装">三、软件安装</h3><p>安装过程很简单就是安装上面的包就可以了，这个包的资源我已经打包好了在这篇的结尾的链接下面，分好了目录,管理节点就安装calamriserver,集群的节点就安装clusternode里面的，出现的冲突的一个包就用rpm -Uvh 升级安装一下，这里面有一个包需要升级安装下<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@myserver centos6calamari]<span class="comment"># ll</span></span><br><span class="line">total <span class="number">8</span></span><br><span class="line">drwxr-xr-x. <span class="number">7</span> root root <span class="number">4096</span> Dec <span class="number">11</span> <span class="number">10</span>:<span class="number">59</span> calamariserver</span><br><span class="line">drwxr-xr-x. <span class="number">4</span> root root <span class="number">4096</span> Dec <span class="number">11</span> <span class="number">11</span>:<span class="number">00</span> clusternode</span><br><span class="line">[root@myserver centos6calamari]<span class="comment"># ll calamariserver/</span></span><br><span class="line">total <span class="number">22092</span></span><br><span class="line">-rw-r--r--. <span class="number">1</span> root root <span class="number">20965336</span> Dec <span class="number">11</span> <span class="number">10</span>:<span class="number">59</span> calamari-server-<span class="number">1.3</span>.<span class="number">1.1</span>-<span class="number">105</span>_g79c8df2.el6.x86_64.rpm</span><br><span class="line">drwxr-xr-x. <span class="number">2</span> root root     <span class="number">4096</span> Dec <span class="number">11</span> <span class="number">10</span>:<span class="number">59</span> httpd</span><br><span class="line">drwxr-xr-x. <span class="number">2</span> root root     <span class="number">4096</span> Dec <span class="number">11</span> <span class="number">10</span>:<span class="number">59</span> postgresql</span><br><span class="line">-rw-r--r--. <span class="number">1</span> root root      <span class="number">658</span> Dec <span class="number">11</span> <span class="number">10</span>:<span class="number">59</span> readme</span><br><span class="line">-rw-r--r--. <span class="number">1</span> root root  <span class="number">1629144</span> Dec <span class="number">11</span> <span class="number">10</span>:<span class="number">59</span> romana-<span class="number">1.2</span>.<span class="number">2</span>-<span class="number">36</span>_gc62bb5b.el6.x86_64.rpm</span><br><span class="line">drwxr-xr-x. <span class="number">2</span> root root     <span class="number">4096</span> Dec <span class="number">11</span> <span class="number">10</span>:<span class="number">59</span> salt-master</span><br><span class="line">drwxr-xr-x. <span class="number">2</span> root root     <span class="number">4096</span> Dec <span class="number">11</span> <span class="number">10</span>:<span class="number">59</span> salt-minion</span><br><span class="line">drwxr-xr-x. <span class="number">2</span> root root     <span class="number">4096</span> Dec <span class="number">11</span> <span class="number">10</span>:<span class="number">59</span> supervisor</span><br><span class="line">[root@myserver centos6calamari]<span class="comment"># ll clusternode/</span></span><br><span class="line">total <span class="number">8</span></span><br><span class="line">drwxr-xr-x. <span class="number">2</span> root root <span class="number">4096</span> Dec <span class="number">11</span> <span class="number">10</span>:<span class="number">59</span> diamond</span><br><span class="line">drwxr-xr-x. <span class="number">3</span> root root <span class="number">4096</span> Dec <span class="number">11</span> <span class="number">11</span>:<span class="number">05</span> salt-minion</span><br></pre></td></tr></table></figure></p>
<p>需要注意一点安装完calamari的server以后需要处理下权限<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@myserver calamari]<span class="comment"># chmod 777 -R /var/log/calamari/</span></span><br><span class="line">[root@myserver calamari]<span class="comment"># chmod 777 -R /opt/calamari/</span></span><br></pre></td></tr></table></figure></p>
<p>然后再去做<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@myserver calamari]<span class="comment">#calamari-ctl initialize</span></span><br></pre></td></tr></table></figure></p>
<h2 id="目前已经测试通过，就是可能我的是虚拟机的原因，会提示web的状态没更新的问题，集群的状态都拿到了">目前已经测试通过，就是可能我的是虚拟机的原因，会提示web的状态没更新的问题，集群的状态都拿到了</h2><h3 id="四、故障排查：">四、故障排查：</h3><p>配置好了后用<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@myserver calamari]<span class="comment"># salt '*' test.ping</span></span><br><span class="line">[root@myserver calamari]<span class="comment"># salt '*' ceph.get_heartbeats</span></span><br></pre></td></tr></table></figure></p>
<p>我的出现了calamari连接了集群发现检测不到集群，就用上面的检测，然后发现确实拿不到集群的信息，然后就去节点的机器上检查salt-minion的日志，发现是一个提示认证的错误，就做了下面的处理后就好了<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@node1 ~]<span class="comment">#rm -rf /etc/salt/pki/minion/minion_master.pub</span></span><br><span class="line">[root@node1 ~]<span class="comment">#service salt-minion restart</span></span><br></pre></td></tr></table></figure></p>
<h3 id="资源链接：">资源链接：</h3><p>链接：<a href="http://pan.baidu.com/s/1eRtLZvO" target="_blank" rel="external">http://pan.baidu.com/s/1eRtLZvO</a> 密码：0ael</p>
<p>资源更新说明：</p>
<ul>
<li>增加了osd限制为256个数的修改patch包，使用rpm -Uvh进行安装，在满足当前的情况下就不需要更新，解决溢出的情况</li>
</ul>
<h3 id="支持链接：">支持链接：</h3><p>如果本文对您有所帮助，可以打赏一点小费，如果您有支持，麻烦在qq上通知一下我</p>
<p>QQ：199383004<br>@运维-武汉-磨磨</p>
<p><img src="http://7xo9we.com1.z0.glb.clouddn.com/zhifubao.png" alt=""></p>
]]></content>
    <summary type="html">
    <![CDATA[<h3 id="一、安装操作系统">一、安装操作系统</h3><p>首先安装操作系统centos6,安装过程选择的是base server，这个不相同不要紧，出现缺少包的时候去iso找出来安装就可以了</p>
<h3 id="二、calamari的简单介绍">二、calamari的简单介绍</h3><p>首先简单的介绍下calamari的这个软件系统的组成，主要是calamari-server,romana，salt-minion，salt-server，diamond，</p>
<p>这些模块各自的作用：</p>
<ul>
<li>calamari-server这个是提供一个与集群进行交互，并且自己封装了一个自己的API，做集中管理的地方，这个只需要在集群当中的某一台机器上安装，也可以独立安装</li>
<li>romana就是原来的calamari-client，这个叫client,其实是一个web的界面，这个叫calamari-web更好，现在已经更名为romana，这个也是只需要在集群当中的某一台机器上安装，也可以独立安装，这个需要跟calamari-server安装在一台机器上</li>
<li>salt-server是一个管理的工具，可以批量的管理其他的机器，可以对安装了salt-minion的机器进行管理，在集群当中，这个也是跟calamari-server安装在一起的</li>
<li>salt-minion是安装在集群的所有节点上的，这个是接收salt-server的指令对集群的机器进行操作，并且反馈一些信息到salt-server上</li>
<li>diamond这个是系统的监控信息的收集控件，提供集群的硬件信息的监控和集群的信息的监控，数据是发送到romana的机器上的，是由romana上的carbon来收取数据并存储到机器当中的数据库当中的</li>
</ul>]]>
    
    </summary>
    
      <category term="ceph" scheme="http://www.zphj1987.com/tags/ceph/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[xenserver使用ceph的rbd的方法]]></title>
    <link href="http://www.zphj1987.com/2015/12/16/xenserver%E4%BD%BF%E7%94%A8ceph%E7%9A%84rbd%E7%9A%84%E6%96%B9%E6%B3%95/"/>
    <id>http://www.zphj1987.com/2015/12/16/xenserver使用ceph的rbd的方法/</id>
    <published>2015-12-16T06:08:00.000Z</published>
    <updated>2015-12-16T06:11:43.964Z</updated>
    <content type="html"><![CDATA[<p>首先安装的xenserver6.5的环境，看到有地方有提到这个上面可以安装rbd的支持，网上有一种方式是libvirt+kvm方式，因为ceph对libviet是原生支持的，但是xenserver底层是xen的，这个就不去研究太多，这个用最简单的方式最好</p>
<p><a href="https://github.com/mstarikov/rbdsr" target="_blank" rel="external">https://github.com/mstarikov/rbdsr</a><br>这个是个第三方的插件，最近才出来的</p>
<p>实现原理是ssh到ceph的机器上获取到可以使用的rbd信息，然后在xenserver的图形界面上通过配置iscsi的方式去配置rbd，里面套用了iscsi的界面，实际去xenserver机器后台同样做的是map的操作<br>这个试了下，界面的操作都可以实现，都可以获取到rbd的信息，但是在最后提交的一下的时候，后台会报错误的信息，这个有可能才出来，还有点问题<br>这个地方可以用其他的方式实现，xenserver在添加硬盘的时候本来就支持的命令行模式，下面为实现方式</p>
<a id="more"></a>
<p>先检查内核的信息，这个有rbd模块，并且用的是3.10的，这个是用的centos7同等的内核，问题不大<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@xenserver ]<span class="comment"># modinfo rbd</span></span><br><span class="line">filename:       /lib/modules/<span class="number">3.10</span>.<span class="number">0</span>+<span class="number">2</span>/kernel/drivers/block/rbd.ko</span><br><span class="line">license:        GPL</span><br><span class="line">author:         Jeff Garzik &lt;jeff@garzik.org&gt;</span><br><span class="line">description:    rados block device</span><br><span class="line">author:         Yehuda Sadeh &lt;yehuda@hq.newdream.net&gt;</span><br><span class="line">author:         Sage Weil &lt;sage@newdream.net&gt;</span><br><span class="line">srcversion:     B03197D54ABE3BD7A32A276</span><br><span class="line">depends:        libceph</span><br><span class="line">intree:         Y</span><br><span class="line">vermagic:       <span class="number">3.10</span>.<span class="number">0</span>+<span class="number">2</span> SMP mod_unload modversions</span><br></pre></td></tr></table></figure></p>
<p>查看系统上软件包的信息，可以看到xenserver6.5虽然用的是centos7同等的内核，实际上环境还是基于centos5的软件版本进行的定制，这个地方本来准备把ceph的软件包安装上去，版本上的依赖相隔太大，就没装了，也没太多的必要，能实现需求即可<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@xenserver]<span class="comment"># rpm -qa|grep ssh</span></span><br><span class="line">openssh-<span class="number">4.3</span>p2-<span class="number">82</span>.el5</span><br></pre></td></tr></table></figure></p>
<p>这个地方在xenserver的机器上使用这个方式使用rbd，需要做下面几个事情：</p>
<ul>
<li>一个是写rbdmap配置文件 </li>
<li>一个是rbdmap启动的脚本 </li>
<li>一个是ceph.conf的配置文件</li>
</ul>
<h3 id="修改/etc/ceph/rbdmap配置文件">修改/etc/ceph/rbdmap配置文件</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/etc/ceph/rbdmap 里面的配置文件书写方式</span><br><span class="line"><span class="comment"># RbdDevice             Parameters</span></span><br><span class="line"><span class="comment">#poolname/imagename     id=client,keyring=/etc/ceph/ceph.client.keyring</span></span><br><span class="line">rbd/testrbd             id=admin</span><br></pre></td></tr></table></figure>
<p>/etc/ceph/rbdmap根据需要去写，我不喜欢用keyring就没写keyring,但是id是必须写，否则会报错</p>
<h3 id="修改rbdmap启动的脚本">修改rbdmap启动的脚本</h3><p>/etc/init.d/rbdmap这个脚本要修改，默认的脚本里面是要去使用rbd命令的，rbd命令是在ceph-common里面的这个里面，可以修改一个不需要安装ceph-common的版本的启动脚本</p>
<p>改版的如下：<br>/etc/init.d/rbdmap文件内容替换如下：<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="shebang">#!/bin/bash</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># rbdmap Ceph RBD Mapping</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># chkconfig: 2345 20 80</span></span><br><span class="line"><span class="comment"># description: Ceph RBD Mapping</span></span><br><span class="line"></span><br><span class="line"><span class="comment">### BEGIN INIT INFO</span></span><br><span class="line"><span class="comment"># Provides:          rbdmap</span></span><br><span class="line"><span class="comment"># Required-Start:    $network</span></span><br><span class="line"><span class="comment"># Required-Stop:     $network</span></span><br><span class="line"><span class="comment"># Default-Start:     2 3 4 5</span></span><br><span class="line"><span class="comment"># Default-Stop:      0 1 6</span></span><br><span class="line"><span class="comment"># Short-Description: Ceph RBD Mapping</span></span><br><span class="line"><span class="comment"># Description:       Ceph RBD Mapping</span></span><br><span class="line"><span class="comment">### END INIT INFO</span></span><br><span class="line"></span><br><span class="line">DESC=<span class="string">"RBD Mapping"</span></span><br><span class="line">RBDMAPFILE=<span class="string">"/etc/ceph/rbdmap"</span></span><br><span class="line"></span><br><span class="line">. /lib/lsb/init-functions</span><br><span class="line"></span><br><span class="line">modprobe rbd || <span class="built_in">exit</span> <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">do_map</span></span>() &#123;</span><br><span class="line">	<span class="keyword">if</span> [ ! <span class="operator">-f</span> <span class="string">"<span class="variable">$RBDMAPFILE</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">		<span class="built_in">echo</span> <span class="string">"<span class="variable">$DESC</span> : No <span class="variable">$RBDMAPFILE</span> found."</span></span><br><span class="line">		<span class="built_in">exit</span> <span class="number">0</span></span><br><span class="line">	<span class="keyword">fi</span></span><br><span class="line"></span><br><span class="line">	<span class="built_in">echo</span> <span class="string">"Starting <span class="variable">$DESC</span>"</span></span><br><span class="line">	<span class="comment"># Read /etc/rbdtab to create non-existant mapping</span></span><br><span class="line">	newrbd=</span><br><span class="line">	RET=<span class="number">0</span></span><br><span class="line">	<span class="keyword">while</span> <span class="built_in">read</span> DEV PARAMS; <span class="keyword">do</span></span><br><span class="line">		<span class="keyword">case</span> <span class="string">"<span class="variable">$DEV</span>"</span> <span class="keyword">in</span></span><br><span class="line">		  <span class="string">""</span>|\<span class="comment">#*)</span></span><br><span class="line">			<span class="built_in">continue</span></span><br><span class="line">			;;</span><br><span class="line">		  */*)</span><br><span class="line">			;;</span><br><span class="line">		  *)</span><br><span class="line">			DEV=rbd/<span class="variable">$DEV</span></span><br><span class="line">			;;</span><br><span class="line">		<span class="keyword">esac</span></span><br><span class="line">		<span class="keyword">if</span> [ ! -b /dev/rbd/<span class="variable">$DEV</span> ]; <span class="keyword">then</span></span><br><span class="line">			<span class="built_in">echo</span> <span class="variable">$DEV</span></span><br><span class="line">			<span class="comment">#rbd map $DEV $CMDPARAMS</span></span><br><span class="line">			mons=`egrep <span class="string">'mon[ _]host'</span> /etc/ceph/ceph.conf | cut <span class="operator">-f</span>2 <span class="operator">-d</span><span class="string">'='</span> | sed <span class="string">'s/ //g'</span>`</span><br><span class="line">			args=`<span class="built_in">echo</span> <span class="variable">$PARAMS</span> | sed <span class="string">'s/id/name/g'</span>`</span><br><span class="line">			rbddev=`<span class="built_in">echo</span> <span class="variable">$DEV</span> | tr <span class="string">'/'</span> <span class="string">' '</span>`</span><br><span class="line">			<span class="built_in">echo</span> <span class="string">"<span class="variable">$mons</span> <span class="variable">$args</span> <span class="variable">$rbddev</span>"</span> &gt; /sys/bus/rbd/add</span><br><span class="line">			[ $? <span class="operator">-ne</span> <span class="string">"0"</span> ] &amp;&amp; RET=<span class="number">1</span></span><br><span class="line">			newrbd=<span class="string">"yes"</span></span><br><span class="line">		<span class="keyword">fi</span></span><br><span class="line">	<span class="keyword">done</span> &lt; <span class="variable">$RBDMAPFILE</span></span><br><span class="line">	<span class="built_in">echo</span> <span class="variable">$RET</span></span><br><span class="line"></span><br><span class="line">	<span class="comment"># Mount new rbd</span></span><br><span class="line">	<span class="keyword">if</span> [ <span class="string">"<span class="variable">$newrbd</span>"</span> ]; <span class="keyword">then</span></span><br><span class="line">                <span class="built_in">echo</span> <span class="string">"Mounting all filesystems"</span></span><br><span class="line">		mount <span class="operator">-a</span></span><br><span class="line">		<span class="built_in">echo</span> $?</span><br><span class="line">	<span class="keyword">fi</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="title">do_unmap</span></span>() &#123;</span><br><span class="line">	<span class="built_in">echo</span> <span class="string">"Stopping <span class="variable">$DESC</span>"</span></span><br><span class="line">	RET=<span class="number">0</span></span><br><span class="line">	<span class="comment"># Recursive umount that depends /dev/rbd*</span></span><br><span class="line"><span class="comment">#原始版本可能没这个命令</span></span><br><span class="line"><span class="comment">#	MNTDEP=$(findmnt --mtab | awk '$2 ~ /^\/dev\/rbd[0-9]*$/ &#123;print $1&#125;' | sort -r)</span></span><br><span class="line"><span class="comment">#修改如下：</span></span><br><span class="line">	MNTDEP=$(mount| awk <span class="string">'$1 ~ /^\/dev\/rbd[0-9]*$/ &#123;print $3&#125;'</span> | sort -r)</span><br><span class="line"></span><br><span class="line">	<span class="keyword">for</span> MNT <span class="keyword">in</span> <span class="variable">$MNTDEP</span>; <span class="keyword">do</span></span><br><span class="line">		umount <span class="variable">$MNT</span></span><br><span class="line">	<span class="keyword">done</span> </span><br><span class="line">	<span class="comment"># Unmap all rbd device</span></span><br><span class="line">	<span class="built_in">cd</span> /sys/bus/rbd/devices/</span><br><span class="line">	<span class="keyword">if</span> ls * &gt;/dev/null <span class="number">2</span>&gt;&amp;<span class="number">1</span>; <span class="keyword">then</span></span><br><span class="line">		<span class="keyword">for</span> DEV <span class="keyword">in</span> *; <span class="keyword">do</span></span><br><span class="line">			<span class="built_in">echo</span> <span class="variable">$DEV</span></span><br><span class="line">			<span class="built_in">echo</span> <span class="variable">$DEV</span> &gt; /sys/bus/rbd/remove</span><br><span class="line">			[ $? <span class="operator">-ne</span> <span class="string">"0"</span> ] &amp;&amp; RET=<span class="number">1</span></span><br><span class="line">		<span class="keyword">done</span></span><br><span class="line">	<span class="keyword">fi</span></span><br><span class="line">	<span class="built_in">echo</span> <span class="variable">$RET</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">case</span> <span class="string">"<span class="variable">$1</span>"</span> <span class="keyword">in</span></span><br><span class="line">  start)</span><br><span class="line">	<span class="keyword">do</span>_map</span><br><span class="line">	;;</span><br><span class="line"></span><br><span class="line">  stop)</span><br><span class="line">	<span class="keyword">do</span>_unmap</span><br><span class="line">	;;</span><br><span class="line"></span><br><span class="line">  reload)</span><br><span class="line">	<span class="keyword">do</span>_map</span><br><span class="line">	;;</span><br><span class="line"></span><br><span class="line">  status)</span><br><span class="line">	ls /sys/bus/rbd/devices/</span><br><span class="line">	;;</span><br><span class="line"></span><br><span class="line">  *)</span><br><span class="line">	<span class="built_in">echo</span> <span class="string">"Usage: rbdmap &#123;start|stop|reload|status&#125;"</span></span><br><span class="line">	<span class="built_in">exit</span> <span class="number">1</span></span><br><span class="line">	;;</span><br><span class="line"><span class="keyword">esac</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">exit</span> <span class="number">0</span></span><br></pre></td></tr></table></figure></p>
<h4 id="使用下面的命令进行rbd的挂载:">使用下面的命令进行rbd的挂载:</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/etc/init.d/rbdmap start</span><br></pre></td></tr></table></figure>
<h4 id="启动后可以查看本地rbd映射的磁盘">启动后可以查看本地rbd映射的磁盘</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@xenserver15 ceph]<span class="comment"># ll /dev/rbd1 </span></span><br><span class="line">brw-r----- <span class="number">1</span> root disk <span class="number">252</span>, <span class="number">0</span> Dec <span class="number">16</span> <span class="number">11</span>:<span class="number">35</span> /dev/rbd1</span><br></pre></td></tr></table></figure>
<h4 id="卸载rbd的命令为">卸载rbd的命令为</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/etc/init.d/rbdmap stop</span><br></pre></td></tr></table></figure>
<h4 id="加入到自启动">加入到自启动</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@xenserver]<span class="comment"># chkconfig rbdmap on</span></span><br></pre></td></tr></table></figure>
<h4 id="检查rbdmap的自启动状态">检查rbdmap的自启动状态</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@xenserver]<span class="comment"># chkconfig --list|grep rbdmap</span></span><br><span class="line">rbdmap         	<span class="number">0</span>:off	<span class="number">1</span>:off	<span class="number">2</span>:on	<span class="number">3</span>:on	<span class="number">4</span>:on	<span class="number">5</span>:on	<span class="number">6</span>:off</span><br></pre></td></tr></table></figure>
<h4 id="将rbdmap从自启动删除">将rbdmap从自启动删除</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@xenserver]<span class="comment"># chkconfig rbdmap off</span></span><br></pre></td></tr></table></figure>
<p>这个地方因为xenserver添加存储的时候选择类型为lvm,而系统默认是识别不了rbdmap到本地的那个文件系统的类型的，所以需要修改一点东西：<br>在/etc/lvm/lvm.conf的98行修改如下<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#types= [ "nvme", 64, "mtip32xx", 64 ]</span></span><br><span class="line"> types= [ <span class="string">"nvme"</span>, <span class="number">64</span>, <span class="string">"mtip32xx"</span>, <span class="number">64</span> , <span class="string">"rbd"</span>, <span class="number">64</span> ]</span><br></pre></td></tr></table></figure></p>
<h4 id="查询新加磁盘的uuid">查询新加磁盘的uuid</h4><p>用绝对路径的时候可能会出现编号错乱的问题，因为/dev/rbd*只是一个软链接<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@xenserver ceph]<span class="comment"># ll /dev/disk/by-uuid/</span></span><br><span class="line">total <span class="number">0</span></span><br><span class="line">lrwxrwxrwx <span class="number">1</span> root root <span class="number">10</span> Dec <span class="number">16</span> <span class="number">11</span>:<span class="number">35</span> <span class="number">0</span>edeba9a-<span class="number">8</span>b58-<span class="number">463</span>c-bdea-<span class="number">0</span>d46e90dd929 -&gt; ../../rbd1</span><br><span class="line">lrwxrwxrwx <span class="number">1</span> root root <span class="number">10</span> Dec  <span class="number">7</span> <span class="number">09</span>:<span class="number">23</span> <span class="number">5170</span>e462-<span class="number">18</span>db-<span class="number">4</span><span class="built_in">fc</span>6<span class="operator">-a</span>45c-dfc160cb86ee -&gt; ../../sda1</span><br></pre></td></tr></table></figure></p>
<h4 id="添加磁盘rbd到xenserver中">添加磁盘rbd到xenserver中</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@xenserver ceph]<span class="comment">#  xe sr-create type=lvm content-type=user device-config:device=/dev/disk/by-uuid/0edeba9a-8b58-463c-bdea-0d46e90dd929 name-label="ceph storage (rbdtest)"</span></span><br></pre></td></tr></table></figure>
<p>然后去图形管理界面就可以看到添加的存储了</p>
<p>到这里就创建好了，这里介绍下删除存储的的操作</p>
<h4 id="列出pdb模块，找到对应存储的UUID">列出pdb模块，找到对应存储的UUID</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">xe pbd-list</span><br></pre></td></tr></table></figure>
<h4 id="找到对应设备的_uuid_卸载对应uuid的存储">找到对应设备的 uuid 卸载对应uuid的存储</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@xenserver ceph]<span class="comment"># xe pbd-unplug uuid="09b97cda-24ad-0a36-8cf7-f7fb0b61cd55"</span></span><br></pre></td></tr></table></figure>
<h4 id="列出存储的UUID，找到对应存储的UUID">列出存储的UUID，找到对应存储的UUID</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@xenserver ceph]<span class="comment"># xe sr-list</span></span><br></pre></td></tr></table></figure>
<h4 id="删除本地存储连接">删除本地存储连接</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@xenserver ceph]<span class="comment"># xe sr-forget uuid=bb24ee6f-e457-685b-f0b9-fe7c92387042</span></span><br></pre></td></tr></table></figure>
<h3 id="对于已经挂载的rbd磁盘的信息查询的问题">对于已经挂载的rbd磁盘的信息查询的问题</h3><p>如果用的是/dev/rbd4</p>
<h4 id="查询存储池">查询存储池</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@xenserver ceph]<span class="comment"># cat /sys/bus/rbd/devices/4/pool_id</span></span><br></pre></td></tr></table></figure>
<h4 id="查询镜像名称">查询镜像名称</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@xenserver ceph]<span class="comment"># cat /sys/bus/rbd/devices/4/name</span></span><br></pre></td></tr></table></figure>
]]></content>
    <summary type="html">
    <![CDATA[<p>首先安装的xenserver6.5的环境，看到有地方有提到这个上面可以安装rbd的支持，网上有一种方式是libvirt+kvm方式，因为ceph对libviet是原生支持的，但是xenserver底层是xen的，这个就不去研究太多，这个用最简单的方式最好</p>
<p><a href="https://github.com/mstarikov/rbdsr">https://github.com/mstarikov/rbdsr</a><br>这个是个第三方的插件，最近才出来的</p>
<p>实现原理是ssh到ceph的机器上获取到可以使用的rbd信息，然后在xenserver的图形界面上通过配置iscsi的方式去配置rbd，里面套用了iscsi的界面，实际去xenserver机器后台同样做的是map的操作<br>这个试了下，界面的操作都可以实现，都可以获取到rbd的信息，但是在最后提交的一下的时候，后台会报错误的信息，这个有可能才出来，还有点问题<br>这个地方可以用其他的方式实现，xenserver在添加硬盘的时候本来就支持的命令行模式，下面为实现方式</p>]]>
    
    </summary>
    
      <category term="ceph" scheme="http://www.zphj1987.com/tags/ceph/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[如何在所有的mon的损坏情况下将数据恢复如初]]></title>
    <link href="http://www.zphj1987.com/2015/12/13/%E5%A6%82%E4%BD%95%E5%9C%A8%E6%89%80%E6%9C%89%E7%9A%84mon%E7%9A%84%E6%8D%9F%E5%9D%8F%E6%83%85%E5%86%B5%E4%B8%8B%E5%B0%86%E6%95%B0%E6%8D%AE%E6%81%A2%E5%A4%8D%E5%A6%82%E5%88%9D/"/>
    <id>http://www.zphj1987.com/2015/12/13/如何在所有的mon的损坏情况下将数据恢复如初/</id>
    <published>2015-12-13T11:26:43.000Z</published>
    <updated>2015-12-13T11:38:08.478Z</updated>
    <content type="html"><![CDATA[<h3 id="本篇主题：">本篇主题：</h3><p>在mon无法启动，或者所有的mon的数据盘都损坏的情况下，如何把所有的数据恢复如初</p>
<h3 id="写本章的缘由">写本章的缘由</h3><p>在ceph中国的群里有看到一个技术人员有提到，在一次意外机房掉电后，三台mon的系统盘同时损坏了，这个对于熟悉ceph的人都知道这意味着什么，所有的集群数据将无法访问，关于这个的解决办法目前没有在哪里有看到，这个对于大多数人是用不上的，但是一旦出现了，这个损失将是无法估量的，当然谁都不希望这个情况的发生<br>所以在研究了下ceph的一些操作后，自己尝试去找了一些关于集群的故障修复的，目前看到了一个是关于单个rbd镜像的恢复的文章，那个需要将数据映射本地的loop设备后重新读取，这个我曾经验证过一遍，确实可以实现，在周末的时候我尝试了另外一个办法，实现了在mon完全失效的情况下全集群的完整数据的恢复，并且保留了原来的数据结构和数据信息，当然这中间需要进行一定的操作去完成它，这个我准备写成一个标准的操作流程，并用视频的方式来记录这个恢复的流程</p>
<h3 id="本篇资源:">本篇资源:</h3><p>包括了视频，操作文档（本篇还未完成，接受预定）</p>
<a id="more"></a>
<h3 id="付费方式：支付宝">付费方式：支付宝</h3><p>10块钱就可以获取，如果你觉得这个帮助你很多，你也可以付多点<br>可以先获取资源，再考虑要不要付费<br>可以付费了后，不满意退费<br>支付码如下：</p>
<p><img src="http://7xo9we.com1.z0.glb.clouddn.com/zhifubao.png" alt=""></p>
<h3 id="资源获取方式：">资源获取方式：</h3><pre><code>qq：199383004
</code></pre><p>资源为百度云链接 </p>
<p>这个视频是不涉及版权的，你可以随便使用，如果你想分享给其他朋友的时候，希望您能让他来我的博客购买</p>
]]></content>
    <summary type="html">
    <![CDATA[<h3 id="本篇主题：">本篇主题：</h3><p>在mon无法启动，或者所有的mon的数据盘都损坏的情况下，如何把所有的数据恢复如初</p>
<h3 id="写本章的缘由">写本章的缘由</h3><p>在ceph中国的群里有看到一个技术人员有提到，在一次意外机房掉电后，三台mon的系统盘同时损坏了，这个对于熟悉ceph的人都知道这意味着什么，所有的集群数据将无法访问，关于这个的解决办法目前没有在哪里有看到，这个对于大多数人是用不上的，但是一旦出现了，这个损失将是无法估量的，当然谁都不希望这个情况的发生<br>所以在研究了下ceph的一些操作后，自己尝试去找了一些关于集群的故障修复的，目前看到了一个是关于单个rbd镜像的恢复的文章，那个需要将数据映射本地的loop设备后重新读取，这个我曾经验证过一遍，确实可以实现，在周末的时候我尝试了另外一个办法，实现了在mon完全失效的情况下全集群的完整数据的恢复，并且保留了原来的数据结构和数据信息，当然这中间需要进行一定的操作去完成它，这个我准备写成一个标准的操作流程，并用视频的方式来记录这个恢复的流程</p>
<h3 id="本篇资源:">本篇资源:</h3><p>包括了视频，操作文档（本篇还未完成，接受预定）</p>]]>
    
    </summary>
    
      <category term="ceph" scheme="http://www.zphj1987.com/tags/ceph/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[关于开始写教程的事]]></title>
    <link href="http://www.zphj1987.com/2015/12/12/%E5%85%B3%E4%BA%8E%E5%BC%80%E5%A7%8B%E5%86%99%E6%95%99%E7%A8%8B%E7%9A%84%E4%BA%8B/"/>
    <id>http://www.zphj1987.com/2015/12/12/关于开始写教程的事/</id>
    <published>2015-12-11T16:37:22.000Z</published>
    <updated>2015-12-11T17:48:30.321Z</updated>
    <content type="html"><![CDATA[<p>在加入到ceph社区的群里以后，尝试着去回答一些有关ceph的问题，发现很多问题其实自己都遇到过，而且很多问题是反复的会被人提起，对于新手来说，由于资源太多，可能就无法比较系统的去学习这个东西，网上的文档也很多，到底从哪里开始，怎么去做，遇到的问题到底是什么造成的，这些都很难一下找到解决办法</p>
<p>有一天想到了是不是自己也可以尝试着去做一下这个事情，网上也会有相关的教程，但是这个实在太少太少，一来专业的讲师可能不会非常的熟悉集群，二来非常熟悉集群的人，也不一定有精力去完成这个事情，而我也不确定能不能很好的去做这个事情，但是总算是起步了</p>
<a id="more"></a>
<p>关于教程，我想一方面需要有视频，一方面是要有很好的文档作为支撑的，最好观看视频的人，可以根据这个文档去一步一步实现视频里面所能实现的东西，作为技术来说文档一般可以很好的去完成一个配置，但是视频的效果也许会更直接，在你还没看完文档的情况下，就能清楚的知道，这个到底是不是我要的，还有一个就是在有时间情况下，我可以对所提到的问题进行反馈</p>
<p>视频的质量自己也不好评判，只是记录了自己的操作，和一些个人的理解，通过相同的操作，能够实现你所想要的，这里面举个最简单的例子，在做ceph的osd的部署的时候，格式化osd的方式就有五种之多，这个对于我自己来说，进行操作的时候，都需要验证几次才能确定这样能去部署好，然后总结下来，当然你可以选择你自己想要的一种即可</p>
<p>前期可能出的都是比较基础的操作，在一定的时候会去尝试讲解一些国外大牛做的ppt，在一些峰会上，总会有一些比较好的经验总结，这些都是值得学习的，有的时候也能提供一些不一样的思路</p>
<p>关于视频，这个我想了下，还是准备收费的，关于收费的问题，这想提出我自己的一个想法，我会在博客中提到我的视频会讲到哪些东西，如果值得看，你就可以通过支付宝的方式进行购买，并告诉我您需要哪个资源，如果你想先看再考虑是不是要付钱，这个也是可以的，如果你付了钱看完了视频，觉得这个视频也就这样，看的东西我都知道，那么你也可以告诉我，我会从支付宝上原路退回的，所以就算这样的：</p>
<p>视频的获取是会收费的，都是10块钱就可以获取，如果你觉得这个帮助你很多，你也可以付多点，这个我不会介意的，这个完全自愿我会发资源链接给你<br>可以先获取资源，再考虑要不要付费<br>也可以付费了后，不满意退费<br>所以，我想这个对于大多数人应该是个可以接受的方式，10块钱不多，当然得由您来判断它的价值了，如果有我的视频没有提到的，而您又比较关心的问题，我也可以尝试做一个新的专题</p>
<p>最后一点，这个视频是不涉及版权的，你可以随便使用，但是如果你想分享给其他朋友的时候，我希望您能让他来我的博客购买，对于购买视频的朋友，我在有空的时候去回答您关于视频当中的问题的，当然我也有我自己的工作，这些可能只能在空余时间进行了</p>
<p>最后希望大家都能成为朋友，毕竟都是这一行的，在不涉及到各自公司的机密技术的情况下，共同进步应该是对整个生态圈是有好处的，好了就写到这里了，欢迎大家多多支持，多多提出宝贵的意见，共同进步</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>在加入到ceph社区的群里以后，尝试着去回答一些有关ceph的问题，发现很多问题其实自己都遇到过，而且很多问题是反复的会被人提起，对于新手来说，由于资源太多，可能就无法比较系统的去学习这个东西，网上的文档也很多，到底从哪里开始，怎么去做，遇到的问题到底是什么造成的，这些都很难一下找到解决办法</p>
<p>有一天想到了是不是自己也可以尝试着去做一下这个事情，网上也会有相关的教程，但是这个实在太少太少，一来专业的讲师可能不会非常的熟悉集群，二来非常熟悉集群的人，也不一定有精力去完成这个事情，而我也不确定能不能很好的去做这个事情，但是总算是起步了</p>]]>
    
    </summary>
    
      <category term="ceph" scheme="http://www.zphj1987.com/tags/ceph/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[ceph集群的安装和配置教程]]></title>
    <link href="http://www.zphj1987.com/2015/12/12/ceph%E9%9B%86%E7%BE%A4%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE%E6%95%99%E7%A8%8B/"/>
    <id>http://www.zphj1987.com/2015/12/12/ceph集群的安装和配置教程/</id>
    <published>2015-12-11T16:36:48.000Z</published>
    <updated>2015-12-11T17:51:41.040Z</updated>
    <content type="html"><![CDATA[<h3 id="本篇主题：">本篇主题：</h3><p>1、怎样配置ssh免登陆访问<br>2、为什么搭建集群要关闭防火墙和selinux，如何关闭<br>3、从哪里获取ceph的安装包，怎样安装才是快速正确的<br>4、为什么要配置时间同步服务，怎样配置<br>5、怎样创建集群<br>6、怎样使用不同的方式增加osd（这里我总结了五种）</p>
<ul>
<li>默认方式</li>
<li>磁盘journal</li>
<li>目录配置方式</li>
<li>btrfs文件系统</li>
<li>disk+ssd方式</li>
</ul>
<p>7、怎样配置文件系统<br>8、怎样配置块设备系统<br>9、怎样配置S3服务<br>10、如何干净的将集群清理到初始状态</p>
<blockquote>
<p>（本篇基于centos7,其他系统除了安装方式其他通用）</p>
</blockquote>
<h3 id="本篇资源:">本篇资源:</h3><p>包括了视频，操作文档，相关安装包资源，S3的windows客户端</p>
<a id="more"></a>
<h3 id="付费方式：支付宝">付费方式：支付宝</h3><p>10块钱就可以获取，如果你觉得这个帮助你很多，你也可以付多点<br>可以先获取资源，再考虑要不要付费<br>可以付费了后，不满意退费<br>支付码如下：</p>
<p><img src="http://7xo9we.com1.z0.glb.clouddn.com/zhifubao.png" alt=""></p>
<h3 id="资源获取方式：">资源获取方式：</h3><pre><code>qq：199383004
</code></pre><p>资源为百度云链接 </p>
<p>这个视频是不涉及版权的，你可以随便使用，如果你想分享给其他朋友的时候，希望您能让他来我的博客购买，对于购买视频的朋友，我在有空的时候去回答您关于视频当中的问题的,在得到您的认可的情况下希望您能推荐更多的人来购买</p>
<hr>
]]></content>
    <summary type="html">
    <![CDATA[<h3 id="本篇主题：">本篇主题：</h3><p>1、怎样配置ssh免登陆访问<br>2、为什么搭建集群要关闭防火墙和selinux，如何关闭<br>3、从哪里获取ceph的安装包，怎样安装才是快速正确的<br>4、为什么要配置时间同步服务，怎样配置<br>5、怎样创建集群<br>6、怎样使用不同的方式增加osd（这里我总结了五种）</p>
<ul>
<li>默认方式</li>
<li>磁盘journal</li>
<li>目录配置方式</li>
<li>btrfs文件系统</li>
<li>disk+ssd方式</li>
</ul>
<p>7、怎样配置文件系统<br>8、怎样配置块设备系统<br>9、怎样配置S3服务<br>10、如何干净的将集群清理到初始状态</p>
<blockquote>
<p>（本篇基于centos7,其他系统除了安装方式其他通用）</p>
</blockquote>
<h3 id="本篇资源:">本篇资源:</h3><p>包括了视频，操作文档，相关安装包资源，S3的windows客户端</p>]]>
    
    </summary>
    
      <category term="ceph" scheme="http://www.zphj1987.com/tags/ceph/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[在线调整ceph的参数]]></title>
    <link href="http://www.zphj1987.com/2015/11/18/%E5%9C%A8%E7%BA%BF%E8%B0%83%E6%95%B4ceph%E7%9A%84%E5%8F%82%E6%95%B0/"/>
    <id>http://www.zphj1987.com/2015/11/18/在线调整ceph的参数/</id>
    <published>2015-11-18T15:11:44.000Z</published>
    <updated>2015-11-18T15:13:22.757Z</updated>
    <content type="html"><![CDATA[<p>能够动态的进行系统参数的调整是一个很重要并且有用的属性<br>ceph的集群提供两种方式的调整，使用tell的方式和daemon设置的方式</p>
<h3 id="一、tell方式设置">一、tell方式设置</h3><p>调整配置使用命令：</p>
<h4 id="调整mon的参数">调整mon的参数</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#ceph tell mon.* injectargs '--&#123;tunable value_to_be_set&#125;'</span></span><br></pre></td></tr></table></figure>
<h4 id="调整osd的参数">调整osd的参数</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#ceph tell osd.* injectargs '--&#123;tunable value_to_be_set&#125;'</span></span><br></pre></td></tr></table></figure>
<h3 id="调整mds的参数">调整mds的参数</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#ceph tell mds.* injectargs '--&#123;tunable value_to_be_set&#125;'</span></span><br></pre></td></tr></table></figure>
<a id="more"></a>
<p>例子：<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@lab5134 ~]<span class="comment"># ceph tell mon.* injectargs '--mon_osd_report_timeout 400'</span></span><br><span class="line">injectargs:mon_osd_report_timeout = <span class="string">'400'</span></span><br></pre></td></tr></table></figure></p>
<p>除了上面的tell的方式调整，还可以使用daemon的方式进行设置</p>
<h3 id="二、daemon方式设置">二、daemon方式设置</h3><h4 id="1、获取当前的参数">1、获取当前的参数</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@lab5134 ~]<span class="comment"># ceph daemon osd.1 config get mon_osd_full_ratio</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"mon_osd_full_ratio"</span>: <span class="string">"0.98"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="2、修改配置">2、修改配置</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@lab5134 ~]<span class="comment"># ceph daemon osd.1 config set mon_osd_full_ratio 0.97</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"success"</span>: <span class="string">"mon_osd_full_ratio = '0.97' "</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="3、检查配置">3、检查配置</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@lab5134 ~]<span class="comment"># ceph daemon osd.1 config get mon_osd_full_ratio</span></span><br><span class="line">&#123;</span><br><span class="line">    <span class="string">"mon_osd_full_ratio"</span>: <span class="string">"0.97"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意重启进程后配置会恢复到默认参数，在进行在线调整后，如果这个参数是后续是需要使用的，那么就需要将相关的参数写入到配置文件ceph.conf当中</p>
<h3 id="两种设置的使用场景">两种设置的使用场景</h3><p>使用tell的方式适合对整个集群进行设置，使用*号进行匹配，就可以对整个集群的角色进行设置，而出现节点异常无法设置时候，只会在命令行当中进行报错，不太便于查找</p>
<p>使用daemon进行设置的方式就是一个个的去设置，这样可以比较好的反馈，这个设置是需要在设置的角色所在的主机上进行设置，daemon的方式还提供通过asok去获取到进行的其他的信息，可以使用 ceph daemon osd.1 help去查询相关的可以使用的命令</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>能够动态的进行系统参数的调整是一个很重要并且有用的属性<br>ceph的集群提供两种方式的调整，使用tell的方式和daemon设置的方式</p>
<h3 id="一、tell方式设置">一、tell方式设置</h3><p>调整配置使用命令：</p>
<h4 id="调整mon的参数">调整mon的参数</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#ceph tell mon.* injectargs '--&#123;tunable value_to_be_set&#125;'</span></span><br></pre></td></tr></table></figure>
<h4 id="调整osd的参数">调整osd的参数</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#ceph tell osd.* injectargs '--&#123;tunable value_to_be_set&#125;'</span></span><br></pre></td></tr></table></figure>
<h3 id="调整mds的参数">调整mds的参数</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment">#ceph tell mds.* injectargs '--&#123;tunable value_to_be_set&#125;'</span></span><br></pre></td></tr></table></figure>]]>
    
    </summary>
    
      <category term="ceph" scheme="http://www.zphj1987.com/tags/ceph/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[验证rbd的缓存是否开启]]></title>
    <link href="http://www.zphj1987.com/2015/11/16/%E9%AA%8C%E8%AF%81rbd%E7%9A%84%E7%BC%93%E5%AD%98%E6%98%AF%E5%90%A6%E5%BC%80%E5%90%AF/"/>
    <id>http://www.zphj1987.com/2015/11/16/验证rbd的缓存是否开启/</id>
    <published>2015-11-16T08:49:16.000Z</published>
    <updated>2016-01-25T09:55:53.136Z</updated>
    <content type="html"><![CDATA[<p>简单快速的在客户端验证rbd的cache是否开启<br>首先修改配置文件<br>在ceph.conf中添加：<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[client]</span><br><span class="line">rbd cache = <span class="literal">true</span></span><br><span class="line">rbd cache writethrough until flush = <span class="literal">true</span></span><br></pre></td></tr></table></figure></p>
<p>开启以后，在这台机器上进行测试<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@node8109 ~]<span class="comment"># rbd -p rbd bench-write zp  --io-size 4096 --io-threads 256  --io-total 102400000   --io-pattern seq</span></span><br><span class="line">bench-write  io_size <span class="number">4096</span> io_threads <span class="number">256</span> bytes <span class="number">102400000</span> pattern seq</span><br><span class="line">  SEC       OPS   OPS/SEC   BYTES/SEC</span><br><span class="line">elapsed:     <span class="number">0</span>  ops:    <span class="number">25000</span>  ops/sec: <span class="number">26830.05</span>  bytes/sec: <span class="number">109895890.09</span></span><br></pre></td></tr></table></figure></p>
<p>可以看到io达到了26830每秒<br><a id="more"></a><br>下面进行关闭后再测试：<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@node8109 ~]<span class="comment"># rbd -p rbd bench-write zp  --io-size 4096 --io-threads 256  --io-total 102400000   --io-pattern seq</span></span><br><span class="line">bench-write  io_size <span class="number">4096</span> io_threads <span class="number">256</span> bytes <span class="number">102400000</span> pattern seq</span><br><span class="line">  SEC       OPS   OPS/SEC   BYTES/SEC</span><br><span class="line">    <span class="number">1</span>       <span class="number">893</span>   <span class="number">1076.16</span>  <span class="number">4407933.78</span></span><br><span class="line">    <span class="number">2</span>      <span class="number">1344</span>    <span class="number">795.81</span>  <span class="number">3259636.35</span></span><br><span class="line">    <span class="number">3</span>      <span class="number">1794</span>    <span class="number">655.20</span>  <span class="number">2683695.60</span></span><br><span class="line">    <span class="number">4</span>      <span class="number">2198</span>    <span class="number">613.23</span>  <span class="number">2511789.77</span></span><br></pre></td></tr></table></figure></p>
<p>可以看到大概只有600左右的IOPS</p>
<p>结论：<br>开启和关闭cache的差别还是很大的，可以通过上面简单的测试来验证rbd的cache是否开启</p>
<p>Power by  Sebastien Han’s blog</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>简单快速的在客户端验证rbd的cache是否开启<br>首先修改配置文件<br>在ceph.conf中添加：<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[client]</span><br><span class="line">rbd cache = <span class="literal">true</span></span><br><span class="line">rbd cache writethrough until flush = <span class="literal">true</span></span><br></pre></td></tr></table></figure></p>
<p>开启以后，在这台机器上进行测试<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@node8109 ~]<span class="comment"># rbd -p rbd bench-write zp  --io-size 4096 --io-threads 256  --io-total 102400000   --io-pattern seq</span></span><br><span class="line">bench-write  io_size <span class="number">4096</span> io_threads <span class="number">256</span> bytes <span class="number">102400000</span> pattern seq</span><br><span class="line">  SEC       OPS   OPS/SEC   BYTES/SEC</span><br><span class="line">elapsed:     <span class="number">0</span>  ops:    <span class="number">25000</span>  ops/sec: <span class="number">26830.05</span>  bytes/sec: <span class="number">109895890.09</span></span><br></pre></td></tr></table></figure></p>
<p>可以看到io达到了26830每秒<br>]]>
    
    </summary>
    
      <category term="ceph" scheme="http://www.zphj1987.com/tags/ceph/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[如何删除一台OSD主机]]></title>
    <link href="http://www.zphj1987.com/2015/11/12/%E5%A6%82%E4%BD%95%E5%88%A0%E9%99%A4%E4%B8%80%E5%8F%B0OSD%E4%B8%BB%E6%9C%BA/"/>
    <id>http://www.zphj1987.com/2015/11/12/如何删除一台OSD主机/</id>
    <published>2015-11-12T13:33:41.000Z</published>
    <updated>2015-11-12T13:35:14.130Z</updated>
    <content type="html"><![CDATA[<blockquote>
<p>在ceph的一台OSD主机出现故障的时候，数据可以通过副本的机制进行恢复，之后通过删除osd的操作也能够将故障osd从osd tree当中删除掉，但是故障的 osd 的主机仍然会留在集群当中，通过 ceph osd tree 或者打印 crush map 都可以看到这个损坏的节点主机名，所以这里讲下怎么删除掉这个无用的host</p>
</blockquote>
<p>首先集群环境为两台主机 node8109 node8110 , node8110主机出现故障需要清理掉</p>
<h4 id="先看下当前的osd_tree状态">先看下当前的osd tree状态</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@node8109 webui]<span class="comment"># ceph osd tree</span></span><br><span class="line">ID WEIGHT  TYPE NAME             UP/DOWN REWEIGHT PRIMARY-AFFINITY </span><br><span class="line">-<span class="number">1</span> <span class="number">4.00000</span> root default                                            </span><br><span class="line">-<span class="number">3</span> <span class="number">4.00000</span>     rack localrack                                      </span><br><span class="line">-<span class="number">2</span> <span class="number">2.00000</span>         host node8109                                   </span><br><span class="line"> <span class="number">0</span> <span class="number">1.00000</span>             osd.<span class="number">0</span>          up  <span class="number">1.00000</span>          <span class="number">1.00000</span> </span><br><span class="line"> <span class="number">1</span> <span class="number">1.00000</span>             osd.<span class="number">1</span>          up  <span class="number">1.00000</span>          <span class="number">1.00000</span> </span><br><span class="line">-<span class="number">4</span> <span class="number">2.00000</span>         host node8110                                   </span><br><span class="line"> <span class="number">2</span> <span class="number">1.00000</span>             osd.<span class="number">2</span>        down  <span class="number">1.00000</span>          <span class="number">1.00000</span> </span><br><span class="line"> <span class="number">3</span> <span class="number">1.00000</span>             osd.<span class="number">3</span>        down  <span class="number">1.00000</span>          <span class="number">1.00000</span></span><br></pre></td></tr></table></figure>
<a id="more"></a>
<h4 id="查看osd的状态">查看osd的状态</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@node8109 webui]<span class="comment"># ceph osd stat</span></span><br><span class="line">     osdmap e66: <span class="number">4</span> osds: <span class="number">2</span> up, <span class="number">4</span> <span class="keyword">in</span>; <span class="number">52</span> remapped pgs</span><br></pre></td></tr></table></figure>
<h4 id="首先out掉osd">首先out掉osd</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@node8109 ~]<span class="comment"># ceph osd out 2</span></span><br><span class="line">marked out osd.<span class="number">2</span>. </span><br><span class="line">[root@node8109 ~]<span class="comment"># ceph osd out 3</span></span><br><span class="line">marked out osd.<span class="number">3</span>.</span><br></pre></td></tr></table></figure>
<h4 id="从crush里面删除osd">从crush里面删除osd</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@node8109 ~]<span class="comment"># ceph osd crush remove osd.2</span></span><br><span class="line">removed item id <span class="number">2</span> name <span class="string">'osd.2'</span> from crush map</span><br><span class="line">[root@node8109 ~]<span class="comment"># ceph osd crush remove osd.3</span></span><br><span class="line">removed item id <span class="number">3</span> name <span class="string">'osd.3'</span> from crush map</span><br></pre></td></tr></table></figure>
<h4 id="从集群中删除OSD">从集群中删除OSD</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@node8109 ~]<span class="comment"># ceph osd rm osd.3</span></span><br><span class="line">removed osd.<span class="number">3</span></span><br><span class="line">[root@node8109 ~]<span class="comment"># ceph osd rm osd.2</span></span><br><span class="line">removed osd.<span class="number">2</span></span><br></pre></td></tr></table></figure>
<h4 id="从集群认证里面删除osd">从集群认证里面删除osd</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@node8109 ~]<span class="comment"># ceph auth del osd.2</span></span><br><span class="line">updated</span><br><span class="line">[root@node8109 ~]<span class="comment"># ceph auth del osd.3</span></span><br><span class="line">updated</span><br></pre></td></tr></table></figure>
<hr>
<p>查看当前的crush map<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">root@node8109 ~]<span class="comment"># ceph osd tree</span></span><br><span class="line">ID WEIGHT  TYPE NAME             UP/DOWN REWEIGHT PRIMARY-AFFINITY </span><br><span class="line">-<span class="number">1</span> <span class="number">2.00000</span> root default                                            </span><br><span class="line">-<span class="number">3</span> <span class="number">2.00000</span>     rack localrack                                      </span><br><span class="line">-<span class="number">2</span> <span class="number">2.00000</span>         host node8109                                   </span><br><span class="line"> <span class="number">0</span> <span class="number">1.00000</span>             osd.<span class="number">0</span>          up  <span class="number">1.00000</span>          <span class="number">1.00000</span> </span><br><span class="line"> <span class="number">1</span> <span class="number">1.00000</span>             osd.<span class="number">1</span>          up  <span class="number">1.00000</span>          <span class="number">1.00000</span> </span><br><span class="line">-<span class="number">4</span>       <span class="number">0</span>         host node8110</span><br></pre></td></tr></table></figure></p>
<p>下面有两种方法从osd tree 删除掉node8110,为命令方式和修改crush map 方式</p>
<h3 id="方式一：命令方式">方式一：命令方式</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@node8109 ~]<span class="comment"># ceph osd crush remove node8110</span></span><br><span class="line">removed item id -<span class="number">4</span> name <span class="string">'node8110'</span> from crush map</span><br><span class="line">[root@node8109 ~]<span class="comment"># ceph osd tree</span></span><br><span class="line">ID WEIGHT  TYPE NAME             UP/DOWN REWEIGHT PRIMARY-AFFINITY </span><br><span class="line">-<span class="number">1</span> <span class="number">2.00000</span> root default                                            </span><br><span class="line">-<span class="number">3</span> <span class="number">2.00000</span>     rack localrack                                      </span><br><span class="line">-<span class="number">2</span> <span class="number">2.00000</span>         host node8109                                   </span><br><span class="line"> <span class="number">0</span> <span class="number">1.00000</span>             osd.<span class="number">0</span>          up  <span class="number">1.00000</span>          <span class="number">1.00000</span> </span><br><span class="line"> <span class="number">1</span> <span class="number">1.00000</span>             osd.<span class="number">1</span>          up  <span class="number">1.00000</span>          <span class="number">1.00000</span></span><br></pre></td></tr></table></figure>
<h3 id="方式二：通过修改_crush_map_的方式">方式二：通过修改 crush map 的方式</h3><h4 id="导出当前的crush_map">导出当前的crush map</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@node8109 ~]<span class="comment">#ceph osd getcrushmap -o crushmap.txt</span></span><br><span class="line">[root@node8109 ~]<span class="comment">#crushtool -d crushmap.txt -o crushmap-decompile</span></span><br><span class="line">[root@node8109 ~]<span class="comment"># vim crushmap-decompile</span></span><br></pre></td></tr></table></figure>
<h4 id="删除掉node8109相关的信息">删除掉node8109相关的信息</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@node8109 ~]<span class="comment">#crushtool -c crushmap-decompile  -o crushmap-compile</span></span><br><span class="line">[root@node8109 ~]<span class="comment"># ceph osd setcrushmap -i crushmap-compile </span></span><br><span class="line"><span class="built_in">set</span> crush map</span><br><span class="line">[root@node8109 ~]<span class="comment"># ceph osd tree</span></span><br><span class="line">ID WEIGHT  TYPE NAME             UP/DOWN REWEIGHT PRIMARY-AFFINITY </span><br><span class="line">-<span class="number">1</span> <span class="number">2.00000</span> root default                                            </span><br><span class="line">-<span class="number">3</span> <span class="number">2.00000</span>     rack localrack                                      </span><br><span class="line">-<span class="number">2</span> <span class="number">2.00000</span>         host node8109                                   </span><br><span class="line"> <span class="number">0</span> <span class="number">1.00000</span>             osd.<span class="number">0</span>          up  <span class="number">1.00000</span>          <span class="number">1.00000</span> </span><br><span class="line"> <span class="number">1</span> <span class="number">1.00000</span>             osd.<span class="number">1</span>          up  <span class="number">1.00000</span>          <span class="number">1.00000</span></span><br></pre></td></tr></table></figure>
<h3 id="总结：">总结：</h3><p>从上面的两种方式可以看出，使用命令的方式更为简单直接，而修改crush map的方式需要去做修改的操作，有一定的修改错误的风险，所以在做crush map的相关操作的时候，建议是能用命令方式做的就用命令方式去做操作</p>
]]></content>
    <summary type="html">
    <![CDATA[<blockquote>
<p>在ceph的一台OSD主机出现故障的时候，数据可以通过副本的机制进行恢复，之后通过删除osd的操作也能够将故障osd从osd tree当中删除掉，但是故障的 osd 的主机仍然会留在集群当中，通过 ceph osd tree 或者打印 crush map 都可以看到这个损坏的节点主机名，所以这里讲下怎么删除掉这个无用的host</p>
</blockquote>
<p>首先集群环境为两台主机 node8109 node8110 , node8110主机出现故障需要清理掉</p>
<h4 id="先看下当前的osd_tree状态">先看下当前的osd tree状态</h4><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@node8109 webui]<span class="comment"># ceph osd tree</span></span><br><span class="line">ID WEIGHT  TYPE NAME             UP/DOWN REWEIGHT PRIMARY-AFFINITY </span><br><span class="line">-<span class="number">1</span> <span class="number">4.00000</span> root default                                            </span><br><span class="line">-<span class="number">3</span> <span class="number">4.00000</span>     rack localrack                                      </span><br><span class="line">-<span class="number">2</span> <span class="number">2.00000</span>         host node8109                                   </span><br><span class="line"> <span class="number">0</span> <span class="number">1.00000</span>             osd.<span class="number">0</span>          up  <span class="number">1.00000</span>          <span class="number">1.00000</span> </span><br><span class="line"> <span class="number">1</span> <span class="number">1.00000</span>             osd.<span class="number">1</span>          up  <span class="number">1.00000</span>          <span class="number">1.00000</span> </span><br><span class="line">-<span class="number">4</span> <span class="number">2.00000</span>         host node8110                                   </span><br><span class="line"> <span class="number">2</span> <span class="number">1.00000</span>             osd.<span class="number">2</span>        down  <span class="number">1.00000</span>          <span class="number">1.00000</span> </span><br><span class="line"> <span class="number">3</span> <span class="number">1.00000</span>             osd.<span class="number">3</span>        down  <span class="number">1.00000</span>          <span class="number">1.00000</span></span><br></pre></td></tr></table></figure>]]>
    
    </summary>
    
      <category term="ceph" scheme="http://www.zphj1987.com/tags/ceph/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Mon失效处理方法]]></title>
    <link href="http://www.zphj1987.com/2015/11/01/Mon%E5%A4%B1%E6%95%88%E5%A4%84%E7%90%86%E6%96%B9%E6%B3%95/"/>
    <id>http://www.zphj1987.com/2015/11/01/Mon失效处理方法/</id>
    <published>2015-11-01T15:34:26.000Z</published>
    <updated>2015-11-01T15:38:49.630Z</updated>
    <content type="html"><![CDATA[<p>假设环境为三个mon，主机名为mon1、mon2、mon3，现在mon3上面的系统盘损坏，mon的数据完全丢失，现在需要对mon3进行恢复处理</p>
<p>1、停止所有mon进程，可以不停其他进程，需要停止内核客户端以及对外的服务，防止卡死<br>在mon1机器上执行<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/etc/init.d/ceph stop mon</span><br></pre></td></tr></table></figure></p>
<p>在mon2机器上执行<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/etc/init.d/ceph stop mon</span><br></pre></td></tr></table></figure></p>
<p>2、分别在mon主机上获取当前的monmap<br>在mon1机器上执行<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph-mon -i mon1 --extract-monmap /tmp/monmap</span><br></pre></td></tr></table></figure></p>
<p>备份原始monmap<br><a id="more"></a><br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cp /tmp/monmap /tmp/monmapbk</span><br></pre></td></tr></table></figure></p>
<p>在mon2机器上执行<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph-mon -i mon2 --extract-monmap /tmp/monmap</span><br></pre></td></tr></table></figure></p>
<p>备份原始monmap<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cp /tmp/monmap /tmp/monmapbk</span><br></pre></td></tr></table></figure></p>
<p>3、处理monmap，去掉损坏的mon3的map信息<br>在mon1机器上执行<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">monmaptool /tmp/monmap --rm mon3</span><br></pre></td></tr></table></figure></p>
<p>在mon2机器上执行<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">monmaptool /tmp/monmap --rm mon3</span><br></pre></td></tr></table></figure></p>
<p>4、导入修改后的monmap信息<br>在mon1机器上执行<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph-mon -i mon1 --inject-monmap /tmp/monmap</span><br></pre></td></tr></table></figure></p>
<p>在mon2机器上执行<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph-mon -i mon1 --inject-monmap /tmp/monmap</span><br></pre></td></tr></table></figure></p>
<p>5、启动mon进程<br>在mon1机器上执行<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/etc/init.d/ceph start mon</span><br></pre></td></tr></table></figure></p>
<p>在mon2机器上执行<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/etc/init.d/ceph start mon</span><br></pre></td></tr></table></figure></p>
<p>6、检查当前的mon信息，应该显示的是只有两个mon,再新加mon即可<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph <span class="operator">-s</span></span><br></pre></td></tr></table></figure></p>
<hr>
<p>写于：2015年11月1日</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>假设环境为三个mon，主机名为mon1、mon2、mon3，现在mon3上面的系统盘损坏，mon的数据完全丢失，现在需要对mon3进行恢复处理</p>
<p>1、停止所有mon进程，可以不停其他进程，需要停止内核客户端以及对外的服务，防止卡死<br>在mon1机器上执行<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/etc/init.d/ceph stop mon</span><br></pre></td></tr></table></figure></p>
<p>在mon2机器上执行<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">/etc/init.d/ceph stop mon</span><br></pre></td></tr></table></figure></p>
<p>2、分别在mon主机上获取当前的monmap<br>在mon1机器上执行<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph-mon -i mon1 --extract-monmap /tmp/monmap</span><br></pre></td></tr></table></figure></p>
<p>备份原始monmap<br>]]>
    
    </summary>
    
      <category term="ceph" scheme="http://www.zphj1987.com/tags/ceph/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[在页面中嵌入自适应视频的方法]]></title>
    <link href="http://www.zphj1987.com/2015/10/13/%E5%9C%A8%E9%A1%B5%E9%9D%A2%E4%B8%AD%E5%B5%8C%E5%85%A5%E8%87%AA%E9%80%82%E5%BA%94%E8%A7%86%E9%A2%91%E7%9A%84%E6%96%B9%E6%B3%95/"/>
    <id>http://www.zphj1987.com/2015/10/13/在页面中嵌入自适应视频的方法/</id>
    <published>2015-10-13T13:50:23.000Z</published>
    <updated>2015-10-13T14:46:32.123Z</updated>
    <content type="html"><![CDATA[<p>准备在博客中嵌入视频，从视频网站获取的embed代码是指定宽度和高度的，这样在一些窗口或者移动端进行访问的时候，就可能视频溢出屏幕了，体验不好，实际上这几年响应式网站比较流行，也就是能让内容自动的适应窗口的大小</p>
<p>屏幕的宽度可以用 <code>width：100%</code> 进行设置，高度看到有个 <code>height:100%</code> 设置后height实际取的是上一层的高度的百分比，如果没设置的话，这个就为0，看到嵌入的视频就没有高度了，网上关于这个的资料很多，可以搜索下</p>
<p>关于视频的自适应看到  <a href="https://developers.google.com/web/fundamentals/media/video/size-videos-correctly?hl=zh-cn#section" title="google 自适应设置建议" target="_blank" rel="external">google 自适应设置建议</a> 这个介绍的很好<br><a id="more"></a><br>主要是这段代码:<br><figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="class">.video-container</span> <span class="rules">&#123;</span><br><span class="line">        <span class="rule"><span class="attribute">position</span>:<span class="value"> relative</span></span>;</span><br><span class="line">        <span class="rule"><span class="attribute">padding-bottom</span>:<span class="value"> <span class="number">56.25%</span></span></span>;</span><br><span class="line">        <span class="rule"><span class="attribute">padding-top</span>:<span class="value"> <span class="number">30px</span></span></span>;</span><br><span class="line">        <span class="rule"><span class="attribute">height</span>:<span class="value"> <span class="number">0</span></span></span>;</span><br><span class="line">        <span class="rule"><span class="attribute">overflow</span>:<span class="value"> hidden</span></span>;</span><br><span class="line">    <span class="rule">&#125;</span></span></span><br><span class="line"></span><br><span class="line">    <span class="class">.video-container</span> <span class="tag">iframe</span>,</span><br><span class="line">    <span class="class">.video-container</span> <span class="tag">object</span>,</span><br><span class="line">    <span class="class">.video-container</span> <span class="tag">embed</span> <span class="rules">&#123;</span><br><span class="line">        <span class="rule"><span class="attribute">position</span>:<span class="value"> absolute</span></span>;</span><br><span class="line">        <span class="rule"><span class="attribute">top</span>:<span class="value"> <span class="number">0</span></span></span>;</span><br><span class="line">        <span class="rule"><span class="attribute">left</span>:<span class="value"> <span class="number">0</span></span></span>;</span><br><span class="line">        <span class="rule"><span class="attribute">width</span>:<span class="value"> <span class="number">100%</span></span></span>;</span><br><span class="line">        <span class="rule"><span class="attribute">height</span>:<span class="value"> <span class="number">100%</span></span></span>;</span><br><span class="line">    <span class="rule">&#125;</span></span></span><br></pre></td></tr></table></figure></p>
<p>上面的56.25%实际是16:9的视频的值，这个可以根据自己的视频高宽比进行设置</p>
<p>我自己的代码是这样的：<br>css的代码<br><figure class="highlight css"><table><tr><td class="code"><pre><span class="line"><span class="class">.article-entry</span> <span class="class">.video-container</span> <span class="rules">&#123;</span><br><span class="line">  <span class="rule"><span class="attribute">position</span>:<span class="value"> relative</span></span>;</span><br><span class="line">  <span class="rule"><span class="attribute">padding-bottom</span>:<span class="value"> <span class="number">56.25%</span></span></span>;</span><br><span class="line">  <span class="rule"><span class="attribute">padding-top</span>:<span class="value"> <span class="number">30px</span></span></span>;</span><br><span class="line">  <span class="rule"><span class="attribute">height</span>:<span class="value"> <span class="number">0</span></span></span>;</span><br><span class="line">  <span class="rule"><span class="attribute">overflow</span>:<span class="value"> hidden</span></span>;</span><br><span class="line"><span class="rule">&#125;</span></span></span><br><span class="line"><span class="class">.article-entry</span> <span class="class">.video-container</span> <span class="tag">embed</span> <span class="rules">&#123;</span><br><span class="line">  <span class="rule"><span class="attribute">position</span>:<span class="value"> absolute</span></span>;</span><br><span class="line">  <span class="rule"><span class="attribute">top</span>:<span class="value"> <span class="number">0</span></span></span>;</span><br><span class="line">  <span class="rule"><span class="attribute">left</span>:<span class="value"> <span class="number">0</span></span></span>;</span><br><span class="line">  <span class="rule"><span class="attribute">width</span>:<span class="value"> <span class="number">100%</span></span></span>;</span><br><span class="line">  <span class="rule"><span class="attribute">height</span>:<span class="value"> <span class="number">100%</span></span></span>;</span><br><span class="line"><span class="rule">&#125;</span></span></span><br><span class="line"><span class="class">.article-entry</span> <span class="class">.video-container</span> <span class="tag">object</span> <span class="rules">&#123;</span><br><span class="line">  <span class="rule"><span class="attribute">position</span>:<span class="value"> absolute</span></span>;</span><br><span class="line">  <span class="rule"><span class="attribute">top</span>:<span class="value"> <span class="number">0</span></span></span>;</span><br><span class="line">  <span class="rule"><span class="attribute">left</span>:<span class="value"> <span class="number">0</span></span></span>;</span><br><span class="line">  <span class="rule"><span class="attribute">width</span>:<span class="value"> <span class="number">100%</span></span></span>;</span><br><span class="line">  <span class="rule"><span class="attribute">height</span>:<span class="value"> <span class="number">100%</span></span></span>;</span><br><span class="line"><span class="rule">&#125;</span></span></span><br></pre></td></tr></table></figure></p>
<p>嵌入的页面html代码为：<br><figure class="highlight"><table><tr><td class="code"><pre><span class="line">&lt;div class="video-container"&gt; &lt;object&gt;</span><br><span class="line">&lt;param name="allowFullScreen" value="true"&gt;&lt;param name="flashVars" value="id=23750026 " /&gt;&lt;param name="movie" value="http://i7.imgs.letv.com/player/swfPlayer.swf?autoplay=0" /&gt;&lt;embed   src="http://i7.imgs.letv.com/player/swfPlayer.swf?autoplay=0" flashVars="id=23750026"allowFullScreen="true" type="application/x-shockwave-flash" &gt;&lt;/embed&gt;&lt;/object&gt;</span><br><span class="line">&lt;/div&gt;</span><br></pre></td></tr></table></figure></p>
<p>添加了一个class标签，去掉了网站视频分享代码里面的width和height的值<br>下面为一个视频的例子：可以调整浏览器查看效果</p>
<div class="video-container"><object><param name="allowFullScreen" value="true"><param name="flashVars" value="id=23739460 "><param name="movie" value="http://i7.imgs.letv.com/player/swfPlayer.swf?autoplay=0"><embed src="http://i7.imgs.letv.com/player/swfPlayer.swf?autoplay=0" flashvars="id=23739460" allowfullscreen="true" type="application/x-shockwave-flash"></object><br></div>

<p><em>ps：测试了很多网站的视频上传，发现还是乐视的清晰度最高，没有压缩很多，并且视频提供高清的观看 </em></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>准备在博客中嵌入视频，从视频网站获取的embed代码是指定宽度和高度的，这样在一些窗口或者移动端进行访问的时候，就可能视频溢出屏幕了，体验不好，实际上这几年响应式网站比较流行，也就是能让内容自动的适应窗口的大小</p>
<p>屏幕的宽度可以用 <code>width：100%</code> 进行设置，高度看到有个 <code>height:100%</code> 设置后height实际取的是上一层的高度的百分比，如果没设置的话，这个就为0，看到嵌入的视频就没有高度了，网上关于这个的资料很多，可以搜索下</p>
<p>关于视频的自适应看到  <a href="https://developers.google.com/web/fundamentals/media/video/size-videos-correctly?hl=zh-cn#section" title="google 自适应设置建议">google 自适应设置建议</a> 这个介绍的很好<br>]]>
    
    </summary>
    
      <category term="杂七杂八" scheme="http://www.zphj1987.com/tags/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[inkscope管理平台试用]]></title>
    <link href="http://www.zphj1987.com/2015/10/12/inkscope%E7%AE%A1%E7%90%86%E5%B9%B3%E5%8F%B0%E8%AF%95%E7%94%A8/"/>
    <id>http://www.zphj1987.com/2015/10/12/inkscope管理平台试用/</id>
    <published>2015-10-12T13:28:22.000Z</published>
    <updated>2015-10-13T14:46:38.365Z</updated>
    <content type="html"><![CDATA[<p>下面为inkscope的管理平台的操作记录，一直听说过这个管理平台，但一直没有真正的去配置过，花了一点时间进行了配置</p>
<p>inkscope的管理平台总结下有下面几个：</p>
<ul>
<li>使用sysprobe获取节点的操作系统监控信息</li>
<li>使用cephprobe去跟ceph集群进行交互，调用了ceph-rest-api进行集群的数据和操作交互</li>
<li>使用mongodb进行监控信息的存储</li>
</ul>
<p>总体来说架构简单，很容易配置，并且官方提供了包，是比较成熟的管理平台了，具体的可以看下面的这个视频<br><a id="more"></a></p>
<div class="video-container"> <object><br><param name="allowFullScreen" value="true"><param name="flashVars" value="id=23750026 "><param name="movie" value="http://i7.imgs.letv.com/player/swfPlayer.swf?autoplay=0"><embed src="http://i7.imgs.letv.com/player/swfPlayer.swf?autoplay=0" flashvars="id=23750026" allowfullscreen="true" type="application/x-shockwave-flash"></object><br></div>

]]></content>
    <summary type="html">
    <![CDATA[<p>下面为inkscope的管理平台的操作记录，一直听说过这个管理平台，但一直没有真正的去配置过，花了一点时间进行了配置</p>
<p>inkscope的管理平台总结下有下面几个：</p>
<ul>
<li>使用sysprobe获取节点的操作系统监控信息</li>
<li>使用cephprobe去跟ceph集群进行交互，调用了ceph-rest-api进行集群的数据和操作交互</li>
<li>使用mongodb进行监控信息的存储</li>
</ul>
<p>总体来说架构简单，很容易配置，并且官方提供了包，是比较成熟的管理平台了，具体的可以看下面的这个视频<br>]]>
    
    </summary>
    
      <category term="ceph" scheme="http://www.zphj1987.com/tags/ceph/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[查询osd上的pg数]]></title>
    <link href="http://www.zphj1987.com/2015/10/04/%E6%9F%A5%E8%AF%A2osd%E4%B8%8A%E7%9A%84pg%E6%95%B0/"/>
    <id>http://www.zphj1987.com/2015/10/04/查询osd上的pg数/</id>
    <published>2015-10-03T16:02:06.000Z</published>
    <updated>2015-10-08T16:13:00.758Z</updated>
    <content type="html"><![CDATA[<p>本文中的命令的第一版来源于国外的一个博客，后面的版本为我自己修改的版本</p>
<p>查询的命令如下：<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph pg dump | awk <span class="string">'</span><br><span class="line"> /^pg_stat/ &#123; col=1; while($col!="up") &#123;col++&#125;; col++ &#125;</span><br><span class="line"> /^[0-9a-f]+\.[0-9a-f]+/ &#123; match($0,/^[0-9a-f]+/); pool=substr($0, RSTART, RLENGTH); poollist[pool]=0;</span><br><span class="line"> up=$col; i=0; RSTART=0; RLENGTH=0; delete osds; while(match(up,/[0-9]+/)&gt;0) &#123; osds[++i]=substr(up,RSTART,RLENGTH); up = substr(up, RSTART+RLENGTH) &#125;</span><br><span class="line"> for(i in osds) &#123;array[osds[i],pool]++; osdlist[osds[i]];&#125;</span><br><span class="line">&#125;</span><br><span class="line">END &#123;</span><br><span class="line"> printf("\n");</span><br><span class="line"> printf("pool :\t"); for (i in poollist) printf("%s\t",i); printf("| SUM \n");</span><br><span class="line"> for (i in poollist) printf("--------"); printf("----------------\n");</span><br><span class="line"> for (i in osdlist) &#123; printf("osd.%i\t", i); sum=0;</span><br><span class="line"> for (j in poollist) &#123; printf("%i\t", array[i,j]); sum+=array[i,j]; poollist[j]+=array[i,j] &#125;; printf("| %i\n",sum) &#125;</span><br><span class="line"> for (i in poollist) printf("--------"); printf("----------------\n");</span><br><span class="line"> printf("SUM :\t"); for (i in poollist) printf("%s\t",poollist[i]); printf("|\n");</span><br><span class="line">&#125;'</span></span><br></pre></td></tr></table></figure></p>
<a id="more"></a>
<p>默认的输出如下：<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">pool :	<span class="number">0</span>	<span class="number">1</span>	<span class="number">2</span>	| SUM </span><br><span class="line">----------------------------------------</span><br><span class="line">osd.<span class="number">4</span>	<span class="number">54</span>	<span class="number">133</span>	<span class="number">79</span>	| <span class="number">266</span></span><br><span class="line">osd.<span class="number">5</span>	<span class="number">57</span>	<span class="number">104</span>	<span class="number">88</span>	| <span class="number">249</span></span><br><span class="line">osd.<span class="number">6</span>	<span class="number">61</span>	<span class="number">132</span>	<span class="number">86</span>	| <span class="number">279</span></span><br><span class="line">osd.<span class="number">7</span>	<span class="number">54</span>	<span class="number">114</span>	<span class="number">85</span>	| <span class="number">253</span></span><br><span class="line">osd.<span class="number">8</span>	<span class="number">63</span>	<span class="number">123</span>	<span class="number">85</span>	| <span class="number">271</span></span><br><span class="line">osd.<span class="number">0</span>	<span class="number">62</span>	<span class="number">120</span>	<span class="number">87</span>	| <span class="number">269</span></span><br><span class="line">osd.<span class="number">1</span>	<span class="number">52</span>	<span class="number">126</span>	<span class="number">81</span>	| <span class="number">259</span></span><br><span class="line">osd.<span class="number">2</span>	<span class="number">52</span>	<span class="number">103</span>	<span class="number">88</span>	| <span class="number">243</span></span><br><span class="line">osd.<span class="number">3</span>	<span class="number">57</span>	<span class="number">125</span>	<span class="number">89</span>	| <span class="number">271</span></span><br><span class="line">----------------------------------------</span><br><span class="line">SUM :	<span class="number">512</span>	<span class="number">1080</span>	<span class="number">768</span>	|</span><br></pre></td></tr></table></figure></p>
<p>这个有个问题就是osd是乱序的，并且对于一个存储池来说不清楚哪个osd的pg是最多的</p>
<h3 id="重构第一版：">重构第一版：</h3><p>跟上面的相比按顺序来排列</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">ceph pg dump | awk <span class="string">'</span><br><span class="line"> /^pg_stat/ &#123; col=1; while($col!="up") &#123;col++&#125;; col++ &#125;</span><br><span class="line"> /^[0-9a-f]+\.[0-9a-f]+/ &#123; match($0,/^[0-9a-f]+/); pool=substr($0, RSTART, RLENGTH); poollist[pool]=0;</span><br><span class="line"> up=$col; i=0; RSTART=0; RLENGTH=0; delete osds; while(match(up,/[0-9]+/)&gt;0) &#123; osds[++i]=substr(up,RSTART,RLENGTH); up = substr(up, RSTART+RLENGTH) &#125;</span><br><span class="line"> for(i in osds) &#123;array[osds[i],pool]++; osdlist[osds[i]];&#125;</span><br><span class="line">&#125;</span><br><span class="line">END &#123;</span><br><span class="line"> printf("\n");</span><br><span class="line"> slen=asorti(poollist,newpoollist);</span><br><span class="line"> printf("pool :\t");for (i=1;i&lt;=slen;i++) &#123;printf("%s\t", newpoollist[i])&#125;; printf("| SUM \n");</span><br><span class="line"> for (i in poollist) printf("--------"); printf("----------------\n");</span><br><span class="line"> slen1=asorti(osdlist,newosdlist)</span><br><span class="line"> delete poollist;</span><br><span class="line"> for (i=1;i&lt;=slen1;i++) &#123; printf("osd.%i\t", newosdlist[i]); sum=0; </span><br><span class="line"> for (j=1;j&lt;=slen;j++)  &#123; printf("%i\t", array[newosdlist[i],newpoollist[j]]); sum+=array[newosdlist[i],newpoollist[j]]; poollist[j]+=array[newosdlist[i],newpoollist[j]] &#125;; printf("| %i\n",sum)</span><br><span class="line">&#125; </span><br><span class="line">for (i in poollist) printf("--------"); printf("----------------\n");</span><br><span class="line">slen2=asorti(poollist,newpoollist);</span><br><span class="line"> printf("SUM :\t"); for (i=1;i&lt;=slen2;i++) printf("%s\t",poollist[newpoollist[i]]); printf("|\n");</span><br><span class="line">&#125;'</span></span><br></pre></td></tr></table></figure>
<p>输出结果为下面的，可以看到现在是按顺序来的，存储池是顺序的，osd编号也是顺序的</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">pool :	<span class="number">0</span>	<span class="number">1</span>	<span class="number">2</span>	| SUM </span><br><span class="line">----------------------------------------</span><br><span class="line">osd.<span class="number">0</span>	<span class="number">62</span>	<span class="number">120</span>	<span class="number">87</span>	| <span class="number">269</span></span><br><span class="line">osd.<span class="number">1</span>	<span class="number">52</span>	<span class="number">126</span>	<span class="number">81</span>	| <span class="number">259</span></span><br><span class="line">osd.<span class="number">2</span>	<span class="number">52</span>	<span class="number">103</span>	<span class="number">88</span>	| <span class="number">243</span></span><br><span class="line">osd.<span class="number">3</span>	<span class="number">57</span>	<span class="number">125</span>	<span class="number">89</span>	| <span class="number">271</span></span><br><span class="line">osd.<span class="number">4</span>	<span class="number">54</span>	<span class="number">133</span>	<span class="number">79</span>	| <span class="number">266</span></span><br><span class="line">osd.<span class="number">5</span>	<span class="number">57</span>	<span class="number">104</span>	<span class="number">88</span>	| <span class="number">249</span></span><br><span class="line">osd.<span class="number">6</span>	<span class="number">61</span>	<span class="number">132</span>	<span class="number">86</span>	| <span class="number">279</span></span><br><span class="line">osd.<span class="number">7</span>	<span class="number">54</span>	<span class="number">114</span>	<span class="number">85</span>	| <span class="number">253</span></span><br><span class="line">osd.<span class="number">8</span>	<span class="number">63</span>	<span class="number">123</span>	<span class="number">85</span>	| <span class="number">271</span></span><br><span class="line">----------------------------------------</span><br><span class="line">SUM :	<span class="number">512</span>	<span class="number">1080</span>	<span class="number">768</span>	|</span><br></pre></td></tr></table></figure>
<h3 id="重构第三版：">重构第三版：</h3><p>包含osd pool的排序，包含osd的排序，输出平均pg数目，输出最大的osd编号，输出超过平均值的百分比</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph pg dump | awk <span class="string">'</span><br><span class="line"> /^pg_stat/ &#123; col=1; while($col!="up") &#123;col++&#125;; col++ &#125;</span><br><span class="line"> /^[0-9a-f]+\.[0-9a-f]+/ &#123; match($0,/^[0-9a-f]+/); pool=substr($0, RSTART, RLENGTH); poollist[pool]=0;</span><br><span class="line"> up=$col; i=0; RSTART=0; RLENGTH=0; delete osds; while(match(up,/[0-9]+/)&gt;0) &#123; osds[++i]=substr(up,RSTART,RLENGTH); up = substr(up, RSTART+RLENGTH) &#125;</span><br><span class="line"> for(i in osds) &#123;array[osds[i],pool]++; osdlist[osds[i]];&#125;</span><br><span class="line">&#125;</span><br><span class="line">END &#123;</span><br><span class="line"> printf("\n");</span><br><span class="line"> slen=asorti(poollist,newpoollist);</span><br><span class="line"> printf("pool :\t");for (i=1;i&lt;=slen;i++) &#123;printf("%s\t", newpoollist[i])&#125;; printf("| SUM \n");</span><br><span class="line"> for (i in poollist) printf("--------"); printf("----------------\n");</span><br><span class="line"> slen1=asorti(osdlist,newosdlist)</span><br><span class="line"> delete poollist;</span><br><span class="line"> for (i=1;i&lt;=slen1;i++) &#123; printf("osd.%i\t", newosdlist[i]); sum=0; </span><br><span class="line"> for (j=1;j&lt;=slen;j++)  &#123; printf("%i\t", array[newosdlist[i],newpoollist[j]]); sum+=array[newosdlist[i],newpoollist[j]]; poollist[j]+=array[newosdlist[i],newpoollist[j]];if(array[newosdlist[i],newpoollist[j]] != 0)&#123;poolhasid[j]+=1 &#125;;if(array[newosdlist[i],newpoollist[j]]&gt;maxpoolosd[j])&#123;maxpoolosd[j]=array[newosdlist[i],newpoollist[j]];maxosdid[j]=newosdlist[i]&#125;&#125;; printf("| %i\n",sum)&#125; </span><br><span class="line">for (i in poollist) printf("--------"); printf("----------------\n");</span><br><span class="line">slen2=asorti(poollist,newpoollist);</span><br><span class="line"> printf("SUM :\t"); for (i=1;i&lt;=slen2;i++) printf("%s\t",poollist[newpoollist[i]]); printf("|\n");</span><br><span class="line"> printf("AVE :\t"); for (i=1;i&lt;=slen2;i++) printf("%d\t",poollist[newpoollist[i]]/poolhasid[i]); printf("|\n");</span><br><span class="line"> printf("max :\t"); for (i=1;i&lt;=slen2;i++) printf("%s\t",maxpoolosd[i]); printf("|\n");</span><br><span class="line"> printf("osdid :\t"); for (i=1;i&lt;=slen2;i++) printf("osd.%s\t",maxosdid[i]); printf("|\n");</span><br><span class="line"> printf("per:\t"); for (i=1;i&lt;=slen2;i++) printf("%.1f%\t",100*(maxpoolosd[i]-poollist[newpoollist[i]]/poolhasid[i])/(poollist[newpoollist[i]]/poolhasid[i])); printf("|\n");</span><br><span class="line">&#125;'</span></span><br></pre></td></tr></table></figure>
<p>输出如下：<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pool :	<span class="number">0</span>	<span class="number">1</span>	<span class="number">2</span>	| SUM </span><br><span class="line">----------------------------------------</span><br><span class="line">osd.<span class="number">0</span>	<span class="number">62</span>	<span class="number">120</span>	<span class="number">87</span>	| <span class="number">269</span></span><br><span class="line">osd.<span class="number">1</span>	<span class="number">52</span>	<span class="number">126</span>	<span class="number">81</span>	| <span class="number">259</span></span><br><span class="line">osd.<span class="number">2</span>	<span class="number">52</span>	<span class="number">103</span>	<span class="number">88</span>	| <span class="number">243</span></span><br><span class="line">osd.<span class="number">3</span>	<span class="number">57</span>	<span class="number">125</span>	<span class="number">89</span>	| <span class="number">271</span></span><br><span class="line">osd.<span class="number">4</span>	<span class="number">54</span>	<span class="number">133</span>	<span class="number">79</span>	| <span class="number">266</span></span><br><span class="line">osd.<span class="number">5</span>	<span class="number">57</span>	<span class="number">104</span>	<span class="number">88</span>	| <span class="number">249</span></span><br><span class="line">osd.<span class="number">6</span>	<span class="number">61</span>	<span class="number">132</span>	<span class="number">86</span>	| <span class="number">279</span></span><br><span class="line">osd.<span class="number">7</span>	<span class="number">54</span>	<span class="number">114</span>	<span class="number">85</span>	| <span class="number">253</span></span><br><span class="line">osd.<span class="number">8</span>	<span class="number">63</span>	<span class="number">123</span>	<span class="number">85</span>	| <span class="number">271</span></span><br><span class="line">----------------------------------------</span><br><span class="line">SUM :	<span class="number">512</span>	<span class="number">1080</span>	<span class="number">768</span>	|</span><br><span class="line">AVE :	<span class="number">56</span>	<span class="number">120</span>	<span class="number">85</span>	|</span><br><span class="line">max :	<span class="number">63</span>	<span class="number">133</span>	<span class="number">89</span>	|</span><br><span class="line">osdid :	osd.<span class="number">8</span>	osd.<span class="number">4</span>	osd.<span class="number">3</span>	|</span><br><span class="line">per:	<span class="number">10.7</span>%	<span class="number">10.8</span>%	<span class="number">4.3</span>%	|</span><br></pre></td></tr></table></figure></p>
<hr>
<p>上面的处理使用的是awk处理，开始的时候看不懂什么意思，然后就去看了这本书 <code>The AWK Programming Language</code> ,网上说这个是awk的圣经，这本书在京东卖1000RMB+,可见这本书的价值，下载地址为： <a href="http://pan.baidu.com/s/1gdwbF71" target="_blank" rel="external">http://pan.baidu.com/s/1gdwbF71</a>，关于原始脚本的意思在这里做一个简单的语法的解释，以及作者脚本的逻辑。</p>
<hr>
<h3 id="语法的解释">语法的解释</h3><blockquote>
<p>/^pg_stat/ { col=1; while($col!=”up”) {col++}; col++ }</p>
</blockquote>
<p>这个是匹配pg dump 的输出结果里面pg_stat那个字段，开始计数为1，不是up值就将col的值加1，这个匹配到的就是我们经常看到的[1,10]这个值最后的col++是将col值+1,因为字段里面有up,up_primary,我们需要的是up_primary</p>
<blockquote>
<p>/^[0-9a-f]+.[0-9a-f]+/ { match($0,/^[0-9a-f]+/); pool=substr($0, RSTART, RLENGTH); poollist[pool]=0;</p>
</blockquote>
<p>这个是匹配前面的 1.17a pg号 ，使用自带的match函数 做字符串的过滤统计匹配.号前面的存储池ID， 并得到 RSTART, RLENGTH 值，这个是取到前面的存储池ID，使用substr 函数，就可以得到pool的值了，poollist[pool]=0，是将数组的值置为0</p>
<blockquote>
<p>up=$col; i=0; RSTART=0; RLENGTH=0; delete osds; while(match(up,/[0-9]+/)&gt;0) { osds[++i]=substr(up,RSTART,RLENGTH); up = substr(up, RSTART+RLENGTH) }</p>
</blockquote>
<p>先将变量置0，然后将osd编号一个个输入到osds[i]的数组当中去</p>
<blockquote>
<p>for(i in osds) {array[osds[i],pool]++; osdlist[osds[i]];}</p>
</blockquote>
<p>将osds数组中的值输入到数组当中去，并且记录成osdlist，和数组array[osd[i],pool]</p>
<blockquote>
<p>printf(“\n”);<br> printf(“pool :\t”); for (i in poollist) printf(“%s\t”,i); printf(“| SUM \n”);</p>
</blockquote>
<p>打印osd pool的编号</p>
<blockquote>
<p>for (i in poollist) printf(“————“); printf(“————————\n”);</p>
</blockquote>
<p>根据osd pool的长度打印——</p>
<blockquote>
<p>for (i in osdlist) { printf(“osd.%i\t”, i); sum=0;</p>
</blockquote>
<p>打印osd的编号</p>
<blockquote>
<p>for (j in poollist) { printf(“%i\t”, array[i,j]); sum+=array[i,j]; poollist[j]+=array[i,j] }; printf(“| %i\n”,sum) }<br>打印对应的osd的pg数目，并做求和的统计</p>
<p>for (i in poollist) printf(“————“); printf(“————————\n”);<br> printf(“SUM :\t”); for (i in poollist) printf(“%s\t”,poollist[i]); printf(“|\n”);</p>
</blockquote>
<p>打印新的poollist里面的求和的值</p>
<p>修改版本里面用到的函数</p>
<blockquote>
<p>slen1=asorti(osdlist,newosdlist)</p>
</blockquote>
<p>这个是将数组里面的下标进行排序，这里是对osd和poollist的编号进行排序 slen1是拿到数组的长度，使用for进行遍历输出</p>
<hr>
<h3 id="脚本的逻辑">脚本的逻辑</h3><ul>
<li>匹配到pg的id和pg对应的osd，</li>
<li>使用数组的方式，将统计到的osd id存储起来，</li>
<li>然后打印数组</li>
</ul>
<hr>
<p>其他资源：<br>pg设置的计算器：<br><a href="http://ceph.com/pgcalc/" target="_blank" rel="external">http://ceph.com/pgcalc/</a><br>pg的查询和设置：<br><a href="http://ceph.com/docs/master/rados/operations/placement-groups/" target="_blank" rel="external">http://ceph.com/docs/master/rados/operations/placement-groups/</a></p>
<hr>
<p>引用博客地址如下：</p>
<p><a href="http://cephnotes.ksperis.com/blog/2015/02/23/get-the-number-of-placement-groups-per-osd/" target="_blank" rel="external">http://cephnotes.ksperis.com/blog/2015/02/23/get-the-number-of-placement-groups-per-osd/</a></p>
]]></content>
    <summary type="html">
    <![CDATA[<p>本文中的命令的第一版来源于国外的一个博客，后面的版本为我自己修改的版本</p>
<p>查询的命令如下：<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">ceph pg dump | awk <span class="string">'</span><br><span class="line"> /^pg_stat/ &#123; col=1; while($col!="up") &#123;col++&#125;; col++ &#125;</span><br><span class="line"> /^[0-9a-f]+\.[0-9a-f]+/ &#123; match($0,/^[0-9a-f]+/); pool=substr($0, RSTART, RLENGTH); poollist[pool]=0;</span><br><span class="line"> up=$col; i=0; RSTART=0; RLENGTH=0; delete osds; while(match(up,/[0-9]+/)&gt;0) &#123; osds[++i]=substr(up,RSTART,RLENGTH); up = substr(up, RSTART+RLENGTH) &#125;</span><br><span class="line"> for(i in osds) &#123;array[osds[i],pool]++; osdlist[osds[i]];&#125;</span><br><span class="line">&#125;</span><br><span class="line">END &#123;</span><br><span class="line"> printf("\n");</span><br><span class="line"> printf("pool :\t"); for (i in poollist) printf("%s\t",i); printf("| SUM \n");</span><br><span class="line"> for (i in poollist) printf("--------"); printf("----------------\n");</span><br><span class="line"> for (i in osdlist) &#123; printf("osd.%i\t", i); sum=0;</span><br><span class="line"> for (j in poollist) &#123; printf("%i\t", array[i,j]); sum+=array[i,j]; poollist[j]+=array[i,j] &#125;; printf("| %i\n",sum) &#125;</span><br><span class="line"> for (i in poollist) printf("--------"); printf("----------------\n");</span><br><span class="line"> printf("SUM :\t"); for (i in poollist) printf("%s\t",poollist[i]); printf("|\n");</span><br><span class="line">&#125;'</span></span><br></pre></td></tr></table></figure></p>]]>
    
    </summary>
    
      <category term="ceph" scheme="http://www.zphj1987.com/tags/ceph/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[rbd的数据在哪里]]></title>
    <link href="http://www.zphj1987.com/2015/09/28/rbd%E7%9A%84%E6%95%B0%E6%8D%AE%E5%9C%A8%E5%93%AA%E9%87%8C/"/>
    <id>http://www.zphj1987.com/2015/09/28/rbd的数据在哪里/</id>
    <published>2015-09-28T08:06:29.000Z</published>
    <updated>2015-09-28T08:21:56.250Z</updated>
    <content type="html"><![CDATA[<h3 id="创建一个rbd">创建一个rbd</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@mytest ~]<span class="comment"># rbd create test1 --size 4000</span></span><br></pre></td></tr></table></figure>
<h3 id="查看rbd信息">查看rbd信息</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@mytest ~]<span class="comment"># rbd info test1</span></span><br><span class="line">rbd image <span class="string">'test1'</span>:</span><br><span class="line">	size <span class="number">4000</span> MB <span class="keyword">in</span> <span class="number">1000</span> objects</span><br><span class="line">	order <span class="number">22</span> (<span class="number">4096</span> kB objects)</span><br><span class="line">	block_name_prefix: rb.<span class="number">0</span>.fa6c.<span class="number">6</span>b8b4567</span><br><span class="line">	format: <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>可以看出是没写入真实数据的<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@mytest ~]<span class="comment"># ceph df|grep rbd</span></span><br><span class="line">    rbd          <span class="number">0</span>       <span class="number">133</span>         <span class="number">0</span>        <span class="number">30627</span>M           <span class="number">2</span></span><br></pre></td></tr></table></figure></p>
<h3 id="查询rbd池里面的对象信息">查询rbd池里面的对象信息</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@mytest ~]<span class="comment"># rados ls -p rbd</span></span><br><span class="line"><span class="built_in">test</span>1.rbd</span><br><span class="line">rbd_directory</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<p>查看下这两个对象的内容<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@mytest ~]<span class="comment">#rados -p rbd get test1.rbd test1rbd.txt</span></span><br><span class="line">[root@mytest ~]<span class="comment"># echo -e `cat test1rbd.txt`</span></span><br><span class="line">&lt;&lt;&lt; Rados Block Device Image &gt;&gt;&gt; rb.<span class="number">0</span>.fa6c.<span class="number">6</span>b8b4567RBD001.<span class="number">005</span></span><br></pre></td></tr></table></figure></p>
<p>这个是记录的rbd镜像的信息<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@mytest ~]<span class="comment"># rados -p rbd get rbd_directory rbddirectory.txt</span></span><br><span class="line">[root@mytest ~]<span class="comment"># echo -e `cat rbddirectory.txt`</span></span><br><span class="line"><span class="built_in">test</span>1</span><br></pre></td></tr></table></figure></p>
<p>这个是记录的rbd的目录信息</p>
<h3 id="rbd映射到本地">rbd映射到本地</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@mytest ~]<span class="comment"># rbd map test1</span></span><br><span class="line">/dev/rbd0</span><br></pre></td></tr></table></figure>
<h3 id="格式化rbd设备">格式化rbd设备</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@mytest ~]<span class="comment"># mkfs.xfs /dev/rbd/rbd/test1 </span></span><br><span class="line"><span class="built_in">log</span> stripe unit (<span class="number">4194304</span> bytes) is too large (maximum is <span class="number">256</span>KiB)</span><br><span class="line"><span class="built_in">log</span> stripe unit adjusted to <span class="number">32</span>KiB</span><br><span class="line">meta-data=/dev/rbd/rbd/<span class="built_in">test</span>1     isize=<span class="number">256</span>    agcount=<span class="number">9</span>, agsize=<span class="number">126976</span> blks</span><br><span class="line">         =                       sectsz=<span class="number">512</span>   attr=<span class="number">2</span>, projid32bit=<span class="number">1</span></span><br><span class="line">         =                       crc=<span class="number">0</span>        finobt=<span class="number">0</span></span><br><span class="line">data     =                       bsize=<span class="number">4096</span>   blocks=<span class="number">1024000</span>, imaxpct=<span class="number">25</span></span><br><span class="line">         =                       sunit=<span class="number">1024</span>   swidth=<span class="number">1024</span> blks</span><br><span class="line">naming   =version <span class="number">2</span>              bsize=<span class="number">4096</span>   ascii-ci=<span class="number">0</span> ftype=<span class="number">0</span></span><br><span class="line"><span class="built_in">log</span>      =internal <span class="built_in">log</span>           bsize=<span class="number">4096</span>   blocks=<span class="number">2560</span>, version=<span class="number">2</span></span><br><span class="line">         =                       sectsz=<span class="number">512</span>   sunit=<span class="number">8</span> blks, lazy-count=<span class="number">1</span></span><br><span class="line">realtime =none                   extsz=<span class="number">4096</span>   blocks=<span class="number">0</span>, rtextents=<span class="number">0</span></span><br></pre></td></tr></table></figure>
<h3 id="查看当前的rbd池里面的对象信息">查看当前的rbd池里面的对象信息</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@mytest mnt]<span class="comment"># rados -p rbd ls</span></span><br><span class="line">rb.<span class="number">0</span>.fa6c.<span class="number">6</span>b8b4567.<span class="number">0000000001</span>f0</span><br><span class="line">rb.<span class="number">0</span>.fa6c.<span class="number">6</span>b8b4567.<span class="number">0000000001</span>f1</span><br><span class="line">rb.<span class="number">0</span>.fa6c.<span class="number">6</span>b8b4567.<span class="number">000000000174</span></span><br><span class="line"><span class="built_in">test</span>1.rbd</span><br><span class="line">rb.<span class="number">0</span>.fa6c.<span class="number">6</span>b8b4567.<span class="number">0000000002</span>e8</span><br><span class="line">rb.<span class="number">0</span>.fa6c.<span class="number">6</span>b8b4567.<span class="number">0000000001</span>f2</span><br><span class="line">rbd_directory</span><br><span class="line">rb.<span class="number">0</span>.fa6c.<span class="number">6</span>b8b4567.<span class="number">0000000000</span>f8</span><br><span class="line">rb.<span class="number">0</span>.fa6c.<span class="number">6</span>b8b4567.<span class="number">0000000003</span>e0</span><br><span class="line">rb.<span class="number">0</span>.fa6c.<span class="number">6</span>b8b4567.<span class="number">000000000000</span></span><br><span class="line">rb.<span class="number">0</span>.fa6c.<span class="number">6</span>b8b4567.<span class="number">00000000007</span>c</span><br><span class="line">rb.<span class="number">0</span>.fa6c.<span class="number">6</span>b8b4567.<span class="number">0000000003</span>e7</span><br><span class="line">rb.<span class="number">0</span>.fa6c.<span class="number">6</span>b8b4567.<span class="number">00000000026</span>c</span><br><span class="line">rb.<span class="number">0</span>.fa6c.<span class="number">6</span>b8b4567.<span class="number">000000000001</span></span><br><span class="line">rb.<span class="number">0</span>.fa6c.<span class="number">6</span>b8b4567.<span class="number">000000000364</span></span><br></pre></td></tr></table></figure>
<p>可以看到格式化过程中写入了一些对象信息，这些应该是存储文件系统信息的，写入的对象，数据的写入的前缀是rb.0.fa6c.6b8b4567</p>
<h3 id="查看对象数据在哪里">查看对象数据在哪里</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@mytest <span class="number">0.1</span>_head]<span class="comment"># ceph osd map rbd rb.0.fa6c.6b8b4567.0000000001f0</span></span><br><span class="line">osdmap e78 pool <span class="string">'rbd'</span> (<span class="number">0</span>) object <span class="string">'rb.0.fa6c.6b8b4567.0000000001f0'</span> -&gt; pg <span class="number">0.1</span>cdfe181 (<span class="number">0.1</span>) -&gt; up ([<span class="number">1</span>], p1) acting ([<span class="number">1</span>], p1)</span><br></pre></td></tr></table></figure>
<p>可以查看到数据是在节点1的pg 0.1 里面</p>
<h3 id="去节点一上查看">去节点一上查看</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@mytest <span class="number">0.1</span>_head]<span class="comment"># ll  /var/lib/ceph/osd/ceph-1/current/0.1_head/</span></span><br><span class="line">total <span class="number">4100</span></span><br><span class="line">-rw-r--r-- <span class="number">1</span> root root       <span class="number">0</span> Aug <span class="number">10</span> <span class="number">14</span>:<span class="number">02</span> __head_00000001__0</span><br><span class="line">-rw-r--r-- <span class="number">1</span> root root <span class="number">4194304</span> Aug <span class="number">23</span> <span class="number">12</span>:<span class="number">36</span> rb.<span class="number">0</span>.fa6c.<span class="number">6</span>b8b4567.<span class="number">0000000001</span>f0__head_1CDFE181__0</span><br></pre></td></tr></table></figure>
<p>可以看到这个对象</p>
<p>上面的步骤实现的是: </p>
<ul>
<li>查看一个rbd image</li>
<li>查看这个image 里面的包含的对象    </li>
<li>查看这个 rbd image的对象在哪个具体的磁盘上</li>
</ul>
<p>无法实现的是查询文件系统之上的某个文件在哪里，这个在cephfs 文件系统接口中是有的</p>
]]></content>
    <summary type="html">
    <![CDATA[<h3 id="创建一个rbd">创建一个rbd</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@mytest ~]<span class="comment"># rbd create test1 --size 4000</span></span><br></pre></td></tr></table></figure>
<h3 id="查看rbd信息">查看rbd信息</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@mytest ~]<span class="comment"># rbd info test1</span></span><br><span class="line">rbd image <span class="string">'test1'</span>:</span><br><span class="line">	size <span class="number">4000</span> MB <span class="keyword">in</span> <span class="number">1000</span> objects</span><br><span class="line">	order <span class="number">22</span> (<span class="number">4096</span> kB objects)</span><br><span class="line">	block_name_prefix: rb.<span class="number">0</span>.fa6c.<span class="number">6</span>b8b4567</span><br><span class="line">	format: <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>可以看出是没写入真实数据的<br><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@mytest ~]<span class="comment"># ceph df|grep rbd</span></span><br><span class="line">    rbd          <span class="number">0</span>       <span class="number">133</span>         <span class="number">0</span>        <span class="number">30627</span>M           <span class="number">2</span></span><br></pre></td></tr></table></figure></p>
<h3 id="查询rbd池里面的对象信息">查询rbd池里面的对象信息</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">[root@mytest ~]<span class="comment"># rados ls -p rbd</span></span><br><span class="line"><span class="built_in">test</span>1.rbd</span><br><span class="line">rbd_directory</span><br></pre></td></tr></table></figure>]]>
    
    </summary>
    
      <category term="ceph" scheme="http://www.zphj1987.com/tags/ceph/"/>
    
  </entry>
  
</feed>
